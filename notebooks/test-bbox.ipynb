{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import glob\n",
    "import logging\n",
    "import math\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Any, Iterable, List, Mapping, Sequence, Tuple, Union\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import PIL.Image as Image\n",
    "\n",
    "import argoverse\n",
    "from argoverse.utils import calibration\n",
    "from argoverse.data_loading.object_label_record import json_label_dict_to_obj_record\n",
    "from argoverse.data_loading.simple_track_dataloader import SimpleArgoverseTrackingDataLoader\n",
    "from argoverse.map_representation.map_api import ArgoverseMap\n",
    "from argoverse.data_loading.argoverse_tracking_loader import ArgoverseTrackingLoader\n",
    "from argoverse.utils.calibration import (\n",
    "    CameraConfig,\n",
    "    get_calibration_config,\n",
    "    point_cloud_to_homogeneous,\n",
    "    project_lidar_to_img_motion_compensated,\n",
    "    project_lidar_to_undistorted_img,\n",
    "    load_calib,\n",
    "    Calibration\n",
    ")\n",
    "from argoverse.utils.camera_stats import (\n",
    "        RING_CAMERA_LIST,\n",
    "        STEREO_CAMERA_LIST,\n",
    "        RING_IMG_HEIGHT,\n",
    "        RING_IMG_WIDTH\n",
    ")\n",
    "from argoverse.utils.city_visibility_utils import clip_point_cloud_to_visible_region\n",
    "from argoverse.utils.cv2_plotting_utils import draw_clipped_line_segment\n",
    "from argoverse.utils.ffmpeg_utils import write_nonsequential_idx_video\n",
    "from argoverse.utils.frustum_clipping import (\n",
    "        generate_frustum_planes,\n",
    "        cuboid_to_2d_frustum_bbox\n",
    ")\n",
    "from argoverse.utils.ply_loader import load_ply\n",
    "from argoverse.utils.se3 import SE3\n",
    "import argoverse.visualization.visualization_utils as viz_util\n",
    "\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#: Any numeric type\n",
    "Number = Union[int, float]\n",
    "\n",
    "name_of_camera = 'ring_front_center'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "a.sort()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps(bbox1_xmin, bbox1_ymin, bbox1_xmax, bbox1_ymax, bbox2_xmin, bbox2_ymin, bbox2_xmax, bbox2_ymax, threshold=0.50):\n",
    "#     print (bbox1_xmin, bbox1_ymin, bbox1_xmax, bbox1_ymax, bbox2_xmin, bbox2_ymin, bbox2_xmax, bbox2_ymax)\n",
    "    if bbox1_xmin > bbox2_xmax or bbox2_xmin > bbox1_xmax: #gap in x\n",
    "        return False\n",
    "    elif bbox2_ymin > bbox2_ymax or bbox2_ymin > bbox1_ymax: #gap in y\n",
    "        return False\n",
    "    else: \n",
    "        area1 = (bbox1_xmax - bbox1_xmin)*(bbox1_ymax - bbox1_ymin)\n",
    "        area2 = (bbox2_xmax - bbox2_xmin)*(bbox2_ymax - bbox2_ymin)\n",
    "        xs = [bbox1_xmin,bbox1_xmax,bbox2_xmin,bbox2_xmax]\n",
    "        ys = [bbox1_ymin,bbox1_ymax,bbox2_ymin,bbox2_ymax]\n",
    "        xs.sort()\n",
    "        ys.sort()\n",
    "        if area1 == 0 or area2 == 0: \n",
    "            print (bbox1_xmin, bbox1_ymin, bbox1_xmax, bbox1_ymax, bbox2_xmin, bbox2_ymin, bbox2_xmax, bbox2_ymax)\n",
    "\n",
    "        area_overlap = (xs[2] - xs[1])*(ys[2] - ys[1]) # interior points are always the overlaping ones\n",
    "#         if max(area_overlap / area1 , area_overlap /area2) > threshold:\n",
    "        if (area_overlap / area1) > threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "# 1710 572 1919 805 1919 558 1919 820\n",
    "def shrink_box(bbox_xmin, bbox_ymin, bbox_xmax, bbox_ymax):\n",
    "    x_avg = (bbox_xmin + bbox_xmax)/2\n",
    "    y_avg = (bbox_ymin + bbox_ymax)/2\n",
    "    return ((bbox_xmin + x_avg)/2, (bbox_ymin + y_avg)/2, (bbox_xmax + x_avg)/2, (bbox_ymax + y_avg)/2)\n",
    "   \n",
    "def ordering(uv1,xmin,ymin,xmax,ymax):\n",
    "    uv1 = uv1.T\n",
    "    xmin,ymin,xmax,ymax = shrink_box(xmin,ymin,xmax,ymax)\n",
    "    lidar_bbox = uv1[(xmin < uv1[:,0]) & (uv1[:,0] < xmax)& (ymin < uv1[:,1]) & (uv1[:,1] < ymax)]\n",
    "    if len(lidar_bbox[:,2]) != 0:\n",
    "        return  np.mean(lidar_bbox[:,2])\n",
    "    else:\n",
    "        return 500\n",
    "\n",
    "\n",
    "def plot_img_2d_bboxes(\n",
    "        labels,\n",
    "        planes,\n",
    "        img_bgr: np.ndarray,\n",
    "        log_calib_data,\n",
    "        camera_name: str,\n",
    "        cam_timestamp: int,\n",
    "        lidar_timestamp: int,\n",
    "        data_dir: str,\n",
    "        log_id: str,\n",
    "        save_img_fpath: str,\n",
    "        lidar_pts,\n",
    "        show_depthmap = False\n",
    "        \n",
    "    \n",
    "):\n",
    "        \"\"\" \"\"\"\n",
    "        ############  Process lidar ###############\n",
    "#         img = argoverse_data.get_image_sync(idx,camera = camera_name)\n",
    "#         objects = argoverse_data.get_label_object(idx)\n",
    "        \n",
    "#         calib = argoverse_data.get_calibration(camera_name) # replace this with manual \n",
    "        \n",
    "        cam_config = get_calibration_config(log_calib_data, camera_name)        \n",
    "        calib_cam = next(\n",
    "            (c for c in log_calib_data[\"camera_data_\"] if c[\"key\"] == f\"image_raw_{camera_name}\"),\n",
    "            None,\n",
    "        )\n",
    "        if calib_cam is None:\n",
    "            print (f\"No Camera of name: {camera_name}\")\n",
    "        calib = Calibration(cam_config, calib_cam)\n",
    "        \n",
    "        \n",
    "#         img_vis = viz_util.show_image_with_boxes(img,objects,calib)\n",
    "#         display(Image.fromarray(img_vis))\n",
    "        # ALMOST DEFINITELY OUT OF SYNC HERE\n",
    "#         pc = argoverse_data.get_lidar(idx)\n",
    "        pc = lidar_pts\n",
    "        uv = calib.project_ego_to_image(pc).T\n",
    "        \n",
    "\n",
    "        idx_ = np.where(np.logical_and.reduce((uv[0, :] >= 0.0, uv[0, :] < np.shape(img_bgr)[1] - 1.0,\n",
    "                                                          uv[1, :] >= 0.0, uv[1, :] < np.shape(img_bgr)[0] - 1.0,\n",
    "                                                          uv[2, :] > 0)))\n",
    "\n",
    "        # uv :: x , y , distance\n",
    "        idx_ = idx_[0]\n",
    "\n",
    "        uv1 =uv[:, idx_]\n",
    "\n",
    "        if uv1 is None:\n",
    "            raise Exception('No point image projection')\n",
    "\n",
    "#         plt.figure(figsize=(10,30))\n",
    "#         plt.imshow(img)\n",
    "        \n",
    "        \n",
    "#         cm = plt.cm.get_cmap('jet')\n",
    "#         plt.scatter(uv1[0], uv1[1], c=1 - uv1[2] / max(uv1[2]), s=1, cmap=cm)\n",
    "#         plt.axis('off')\n",
    "#         plt.savefig(\"base_\"+save_img_fpath)\n",
    "#         plt.clf()\n",
    "#         assert 1 == 2\n",
    "        \n",
    "        bboxes = []\n",
    "        \n",
    "        for label_idx, label in enumerate(labels):\n",
    "                obj_rec = json_label_dict_to_obj_record(label)\n",
    "                if obj_rec.label_class in [\"ANIMAL\", \"STROLLER\", \"OTHER_MOVER\", \"ON_ROAD_OBSTACLE\"]:\n",
    "                        continue                \n",
    "                if obj_rec.occlusion == 100:\n",
    "                        continue\n",
    "                if obj_rec.occlusion > 0:\n",
    "                        print(\"Occlusion {}\".format(obj_rec.occlusion))\n",
    "\n",
    "                cuboid_vertices = obj_rec.as_3d_bbox()\n",
    "                points_h = point_cloud_to_homogeneous(cuboid_vertices).T\n",
    "\n",
    "                uv, uv_cam, valid_pts_bool, camera_config = project_lidar_to_img_motion_compensated(\n",
    "                        points_h,  # these are recorded at lidar_time\n",
    "                        copy.deepcopy(log_calib_data),\n",
    "                        camera_name,\n",
    "                        cam_timestamp,\n",
    "                        lidar_timestamp,\n",
    "                        data_dir,\n",
    "                        log_id,\n",
    "                        return_K=True,\n",
    "                )\n",
    "                K = camera_config.intrinsic\n",
    "\n",
    "                if valid_pts_bool.sum() == 0:\n",
    "                    continue\n",
    "                bbox_2d = cuboid_to_2d_frustum_bbox(uv_cam.T[:,:3], planes, K[:3,:3])\n",
    "                if bbox_2d is None:\n",
    "                        continue\n",
    "                else:\n",
    "                        x1,y1,x2,y2 = bbox_2d\n",
    "\n",
    "                        x1 = min(x1,RING_IMG_WIDTH-1)\n",
    "                        x2 = min(x2,RING_IMG_WIDTH-1)\n",
    "                        y1 = min(y1,RING_IMG_HEIGHT-1)\n",
    "                        y2 = min(y2,RING_IMG_HEIGHT-1)\n",
    "\n",
    "                        x1 = max(x1, 0)\n",
    "                        x2 = max(x2, 0)\n",
    "                        y1 = max(y1, 0)\n",
    "                        y2 = max(y2, 0)\n",
    "\n",
    "                        xmin = min(x1, x2)\n",
    "                        xmax = max(x1, x2)\n",
    "                        ymin = min(y1, y2)\n",
    "                        ymax = max(y1, y2)\n",
    "                        start = (int(xmin), int(ymin))\n",
    "                        end = (int(xmax), int(ymax))\n",
    "                        if xmin != xmax and ymin != ymax: #get rid of zero area boxes\n",
    "                            bboxes.append((start,end))\n",
    "                        \n",
    "                        \n",
    "#                         cv2.rectangle(img_bgr, start, end, (0, 0, 255))\n",
    "\n",
    "        average_depth = [ ordering(uv1, xmin,ymin,xmax,ymax) for (xmin,ymin),(xmax,ymax) in bboxes]\n",
    "        new_bboxes = []\n",
    "#         print (bboxes[40], bboxes[0])\n",
    "#         (xmin,ymin), (xmax,ymax) = bboxes[40]\n",
    "#         (x_min, y_min), (x_max,y_max) = bboxes[0]\n",
    "#         print (overlaps(xmin,ymin,xmax,ymax,x_min,y_min,x_max,y_max))\n",
    "        for i in range(len(bboxes)):\n",
    "            (bbox1_xmin, bbox1_ymin), (bbox1_xmax, bbox1_ymax) = bboxes[i]\n",
    "            is_occluded = False\n",
    "            for j  in range(len(bboxes)):\n",
    "                if i != j:\n",
    "                    (bbox2_xmin, bbox2_ymin), (bbox2_xmax, bbox2_ymax) = bboxes[j]\n",
    "                    if overlaps(bbox1_xmin, bbox1_ymin, bbox1_xmax, bbox1_ymax, bbox2_xmin, bbox2_ymin, bbox2_xmax, bbox2_ymax):\n",
    "                        is_occluded = is_occluded or (average_depth[j] < average_depth[i])\n",
    "#                         print (f\"{i} occludes {j}\")\n",
    "            if is_occluded == False:\n",
    "                new_bboxes.append(((bbox1_xmin, bbox1_ymin), (bbox1_xmax, bbox1_ymax)))\n",
    "\n",
    "        for bbox_start, bbox_end in new_bboxes:\n",
    "            cv2.rectangle(img_bgr,bbox_start, bbox_end, (0,0,255))\n",
    "        \n",
    "        img = Image.fromarray(img_bgr[:,:,::-1])\n",
    "        img.save(save_img_fpath)\n",
    "        if show_depthmap:\n",
    "            plt.imshow(img)        \n",
    "            cm = plt.cm.get_cmap('jet')\n",
    "            plt.scatter(uv1[0], uv1[1], c=1 - uv1[2] / max(uv1[2]), s=1, cmap=cm)\n",
    "            plt.axis('off')\n",
    "            plt.savefig(\"base_\"+save_img_fpath)\n",
    "            plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_log_2d_bboxes_to_imgs(\n",
    "    log_ids: Sequence[str],\n",
    "    max_num_images_to_render: int,\n",
    "    data_dir: str,\n",
    "    experiment_prefix: str,\n",
    "    motion_compensate: bool = True,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    We bring the 3D points into each camera coordinate system, and do the clipping there in 3D.\n",
    "\n",
    "    Args:\n",
    "        log_ids: A list of log IDs\n",
    "        max_num_images_to_render: maximum numbers of images to render.\n",
    "        data_dir: path to dataset with the latest data\n",
    "        experiment_prefix: Output directory\n",
    "        motion_compensate: Whether to motion compensate when projecting\n",
    "\n",
    "    Returns:\n",
    "        saved_img_fpaths\n",
    "    \"\"\"\n",
    "    saved_img_fpaths = []\n",
    "    dl = SimpleArgoverseTrackingDataLoader(data_dir=data_dir, labels_dir=data_dir)\n",
    "    avm = ArgoverseMap()\n",
    "\n",
    "    for log_id in log_ids:\n",
    "        save_dir = f\"{experiment_prefix}_{log_id}\"\n",
    "        if not Path(save_dir).exists():\n",
    "            os.makedirs(save_dir)\n",
    "            \n",
    "        # JUSTIN: For base image as I'm solivng sync issues\n",
    "        if not Path(\"base_\"+save_dir).exists():\n",
    "            os.makedirs(\"base_\"+save_dir)\n",
    "\n",
    "        city_name = dl.get_city_name(log_id)\n",
    "        log_calib_data = dl.get_log_calibration_data(log_id)\n",
    "\n",
    "        flag_done = False\n",
    "        for cam_idx, camera_name in enumerate(RING_CAMERA_LIST + STEREO_CAMERA_LIST):\n",
    "            \n",
    "            if camera_name != name_of_camera:\n",
    "                continue\n",
    "\n",
    "            print (dl.data_dir, log_id,camera_name)\n",
    "            cam_im_fpaths = dl.get_ordered_log_cam_fpaths(log_id, camera_name)\n",
    "            print (len(cam_im_fpaths), log_id, camera_name)\n",
    "            for i, im_fpath in enumerate(cam_im_fpaths):\n",
    "                \n",
    "                if i % 50 == 0:\n",
    "                    logging.info(\"\\tOn file %s of camera %s of %s\", i, camera_name, log_id)\n",
    "\n",
    "                cam_timestamp = Path(im_fpath).stem.split(\"_\")[-1]\n",
    "                cam_timestamp = int(cam_timestamp)\n",
    "\n",
    "                # load PLY file path, e.g. 'PC_315978406032859416.ply'\n",
    "                ply_fpath = dl.get_closest_lidar_fpath(log_id, cam_timestamp)\n",
    "                if ply_fpath is None:\n",
    "                    print (\"break at no_fpath\")\n",
    "                    continue\n",
    "                lidar_pts = load_ply(ply_fpath)# here we get lidar points\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                save_img_fpath = f\"{save_dir}/{camera_name}_{cam_timestamp}.jpg\"\n",
    "#                 save_img_fpath = f\"{save_dir}/{camera_name}_{i}.jpg\"\n",
    "                print (f\"Saving to {save_img_fpath}\")\n",
    "                if Path(save_img_fpath).exists():\n",
    "                        print (\"path exists exit\")\n",
    "                        continue\n",
    "\n",
    "                city_to_egovehicle_se3 = dl.get_city_to_egovehicle_se3(log_id, cam_timestamp)\n",
    "                if city_to_egovehicle_se3 is None:\n",
    "                    print (\"break at city_to_egovehicle\")\n",
    "                    continue\n",
    "\n",
    "                lidar_timestamp = Path(ply_fpath).stem.split(\"_\")[-1]\n",
    "                lidar_timestamp = int(lidar_timestamp)\n",
    "                labels = dl.get_labels_at_lidar_timestamp(log_id, lidar_timestamp)\n",
    "                if labels is None:\n",
    "                    logging.info(\"\\tLabels missing at t=%s\", lidar_timestamp)\n",
    "                    print(\"break at missing label\")\n",
    "                    continue\n",
    "\n",
    "                # Swap channel order as OpenCV expects it -- BGR not RGB\n",
    "                # must make a copy to make memory contiguous\n",
    "                img_bgr = imageio.imread(im_fpath)[:, :, ::-1].copy()\n",
    "                camera_config = get_calibration_config(log_calib_data, camera_name)\n",
    "                planes = generate_frustum_planes(camera_config.intrinsic.copy(), camera_name)\n",
    "\n",
    "#                 print(\"We about to plot\")\n",
    "                plot_img_2d_bboxes(labels, planes, img_bgr, log_calib_data, \n",
    "                                   camera_name, cam_timestamp, lidar_timestamp, data_dir, \n",
    "                                   log_id, save_img_fpath,\n",
    "                                   lidar_pts\n",
    "                                  )\n",
    "\n",
    "#                 print (\"Finished plotting\")\n",
    "                if i > 400:\n",
    "                        break\n",
    "\n",
    "        category_subdir = \"2d_amodal_labels_100fr\"\n",
    "\n",
    "        if not Path(f\"{experiment_prefix}_{category_subdir}\").exists():\n",
    "            os.makedirs(f\"{experiment_prefix}_{category_subdir}\")\n",
    "\n",
    "        for cam_idx, camera_name in enumerate(RING_CAMERA_LIST + STEREO_CAMERA_LIST):\n",
    "            # Write the cuboid video -- could also write w/ fps=20,30,40\n",
    "            if camera_name != name_of_camera:\n",
    "                continue\n",
    "            if \"stereo\" in camera_name:\n",
    "                fps = 5\n",
    "            else:\n",
    "                fps = 30\n",
    "            img_wildcard = f\"{save_dir}/{camera_name}_%*.jpg\"\n",
    "            output_fpath = f\"{experiment_prefix}_{category_subdir}/{log_id}_{camera_name}_{fps}fps.mp4\"\n",
    "\n",
    "            write_nonsequential_idx_video(img_wildcard, output_fpath, fps)\n",
    "\n",
    "            print (img_wildcard, output_fpath,fps)\n",
    "            print (\"###################### HERE #####################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/wong.justin/argo/argoverse-tracking/train1/ 6f153f9c-edc5-389f-ac6f-40705c30d97e ring_front_center\n",
      "463 6f153f9c-edc5-389f-ac6f-40705c30d97e ring_front_center\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434214396776.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434247696632.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434280996408.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434314296296.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434347596072.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434380895928.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434414195816.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434447495592.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434480795368.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434514095336.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434547395112.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434580694888.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434613994776.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434647294632.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434680594408.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434713894296.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434747194072.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434780493928.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434813793816.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434847093592.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434880393368.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434913693336.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434946993112.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966434980292888.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435013592776.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435046892632.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435080192408.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435113492296.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435146792072.jpg\n",
      "path exists exit\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435180091928.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435213391816.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435246691592.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435279991368.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435313291256.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435346591112.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435379890888.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435413190776.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435446490552.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435479790408.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435513090296.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435546390072.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435579689960.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435612989736.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435646289592.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435679589480.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435712889312.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435746189480.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435779489704.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435812789952.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435846090120.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435879390344.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435912690512.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435945990680.jpg\n",
      "Saving to depth_6f153f9c-edc5-389f-ac6f-40705c30d97e/ring_front_center_315966435979290984.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-327e89a694c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/data/wong.justin/argo/argoverse-tracking/train1/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mexperiment_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'depth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mdump_log_2d_bboxes_to_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_num_images_to_render\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-c9f93c9ac6ff>\u001b[0m in \u001b[0;36mdump_log_2d_bboxes_to_imgs\u001b[0;34m(log_ids, max_num_images_to_render, data_dir, experiment_prefix, motion_compensate)\u001b[0m\n\u001b[1;32m     92\u001b[0m                                    \u001b[0mcamera_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcam_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlidar_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                                    \u001b[0mlog_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_img_fpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                                    \u001b[0mlidar_pts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                                   )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-f5531dc22f77>\u001b[0m in \u001b[0;36mplot_img_2d_bboxes\u001b[0;34m(labels, planes, img_bgr, log_calib_data, camera_name, cam_timestamp, lidar_timestamp, data_dir, log_id, save_img_fpath, lidar_pts, show_depthmap)\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Occlusion {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mocclusion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0mcuboid_vertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_3d_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0mpoints_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoint_cloud_to_homogeneous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuboid_vertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/argoverse-api/argoverse/data_loading/object_label_record.py\u001b[0m in \u001b[0;36mas_3d_bbox\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0my_corners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mz_corners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mcorners_object_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0megovehicle_SE3_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSE3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquat2rotmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquaternion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# def main(args: Any):\n",
    "#     \"\"\"Run the example.\"\"\"\n",
    "#     log_ids = [log_id.strip() for log_id in args.log_ids.split(\",\")]\n",
    "#     dump_log_2d_bboxes_to_imgs(\n",
    "#         log_ids, args.max_num_images_to_render * 9, args.dataset_dir, args.experiment_prefix\n",
    "#     )\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Parse command line arguments\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\n",
    "#         \"--max-num-images-to-render\", default=5, type=int, help=\"number of images within which to render 3d cuboids\"\n",
    "#     )\n",
    "#     parser.add_argument(\"--dataset-dir\", type=str, required=True, help=\"path to the dataset folder\")\n",
    "#     parser.add_argument(\n",
    "#         \"--log-ids\",\n",
    "#         type=str,\n",
    "#         required=True,\n",
    "#         help=\"comma separated list of log ids, each log_id represents a log directory, e.g. found at \"\n",
    "#         \" {args.dataset-dir}/argoverse-tracking/train/{log_id} or \"\n",
    "#         \" {args.dataset-dir}/argoverse-tracking/sample/{log_id} or \",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--experiment-prefix\",\n",
    "#         default=\"output\",\n",
    "#         type=str,\n",
    "#         help=\"results will be saved in a folder with this prefix for its name\",\n",
    "#     )\n",
    "#     args = parser.parse_args()\n",
    "#     logger.info(args)\n",
    "\n",
    "#     if args.log_ids is None:\n",
    "#         logger.error(f\"Please provide a comma seperated list of log ids\")\n",
    "#         raise ValueError(f\"Please provide a comma seperated list of log ids\")\n",
    "\n",
    "#     main(args)\n",
    "log_ids = ['6f153f9c-edc5-389f-ac6f-40705c30d97e']\n",
    "max_num_images_to_render = 1\n",
    "dataset_dir = '/data/wong.justin/argo/argoverse-tracking/train1/'\n",
    "experiment_prefix = 'depth'\n",
    "dump_log_2d_bboxes_to_imgs(log_ids,max_num_images_to_render*9, dataset_dir, experiment_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
