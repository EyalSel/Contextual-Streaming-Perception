{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario X Config -> score training with Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.environ[\"MODIN_ENGINE\"] = \"ray\"\n",
    "# import modin.pandas as modin_pd\n",
    "\n",
    "# import dask.dataframe as dd\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from ad_config_search.utils import get_rows\n",
    "RSEED = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tables and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>D-model</th>\n",
       "      <th>D-conf</th>\n",
       "      <th>D-seq-pol</th>\n",
       "      <th>T-model</th>\n",
       "      <th>T-min-iou</th>\n",
       "      <th>T-max-age</th>\n",
       "      <th>T-every-nth-det</th>\n",
       "      <th>score</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training_0000-S23-P0_5</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30.547550</td>\n",
       "      <td>T_mota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training_0000-S23-P1_5</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.197930</td>\n",
       "      <td>T_mota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training_0000-S23-P2_5</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>37.049861</td>\n",
       "      <td>T_mota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>training_0000-S23-P3_5</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28.266494</td>\n",
       "      <td>T_mota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>training_0000-S23-P4_5</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>29.371688</td>\n",
       "      <td>T_mota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704955</th>\n",
       "      <td>training_0003-S1-P0_5</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-9.959350</td>\n",
       "      <td>T_mota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704956</th>\n",
       "      <td>training_0003-S1-P1_5</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.034682</td>\n",
       "      <td>T_mota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704957</th>\n",
       "      <td>training_0003-S1-P2_5</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.264901</td>\n",
       "      <td>T_mota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704958</th>\n",
       "      <td>training_0003-S1-P3_5</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-27.734375</td>\n",
       "      <td>T_mota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704959</th>\n",
       "      <td>training_0003-S1-P4_5</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-45.783133</td>\n",
       "      <td>T_mota</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1704960 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            run          D-model  D-conf D-seq-pol T-model  \\\n",
       "0        training_0000-S23-P0_5  efficientdet-d5     0.5     eager    sort   \n",
       "1        training_0000-S23-P1_5  efficientdet-d5     0.5     eager    sort   \n",
       "2        training_0000-S23-P2_5  efficientdet-d5     0.5     eager    sort   \n",
       "3        training_0000-S23-P3_5  efficientdet-d5     0.5     eager    sort   \n",
       "4        training_0000-S23-P4_5  efficientdet-d5     0.5     eager    sort   \n",
       "...                         ...              ...     ...       ...     ...   \n",
       "1704955   training_0003-S1-P0_5  efficientdet-d6     0.3     eager    sort   \n",
       "1704956   training_0003-S1-P1_5  efficientdet-d6     0.3     eager    sort   \n",
       "1704957   training_0003-S1-P2_5  efficientdet-d6     0.3     eager    sort   \n",
       "1704958   training_0003-S1-P3_5  efficientdet-d6     0.3     eager    sort   \n",
       "1704959   training_0003-S1-P4_5  efficientdet-d6     0.3     eager    sort   \n",
       "\n",
       "         T-min-iou  T-max-age  T-every-nth-det      score  metric  \n",
       "0              0.3          5                1  30.547550  T_mota  \n",
       "1              0.3          5                1  39.197930  T_mota  \n",
       "2              0.3          5                1  37.049861  T_mota  \n",
       "3              0.3          5                1  28.266494  T_mota  \n",
       "4              0.3          5                1  29.371688  T_mota  \n",
       "...            ...        ...              ...        ...     ...  \n",
       "1704955        0.5          3                3  -9.959350  T_mota  \n",
       "1704956        0.5          3                3  -3.034682  T_mota  \n",
       "1704957        0.5          3                3 -10.264901  T_mota  \n",
       "1704958        0.5          3                3 -27.734375  T_mota  \n",
       "1704959        0.5          3                3 -45.783133  T_mota  \n",
       "\n",
       "[1704960 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in data\n",
    "with open(\"df_configs_5sectors.pl\", 'rb') as f:\n",
    "    config_df = pickle.load(f)\n",
    "config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>D-model</th>\n",
       "      <th>D-conf</th>\n",
       "      <th>D-seq-pol</th>\n",
       "      <th>T-model</th>\n",
       "      <th>T-min-iou</th>\n",
       "      <th>T-max-age</th>\n",
       "      <th>T-every-nth-det</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training_0000-S23-P0_5</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30.547550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training_0000-S23-P1_5</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.197930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training_0000-S23-P2_5</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>37.049861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>training_0000-S23-P3_5</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28.266494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>training_0000-S23-P4_5</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>29.371688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704955</th>\n",
       "      <td>training_0003-S1-P0_5</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-9.959350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704956</th>\n",
       "      <td>training_0003-S1-P1_5</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.034682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704957</th>\n",
       "      <td>training_0003-S1-P2_5</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.264901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704958</th>\n",
       "      <td>training_0003-S1-P3_5</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-27.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704959</th>\n",
       "      <td>training_0003-S1-P4_5</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-45.783133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1704960 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            run          D-model  D-conf D-seq-pol T-model  \\\n",
       "0        training_0000-S23-P0_5  efficientdet-d5     0.5     eager    sort   \n",
       "1        training_0000-S23-P1_5  efficientdet-d5     0.5     eager    sort   \n",
       "2        training_0000-S23-P2_5  efficientdet-d5     0.5     eager    sort   \n",
       "3        training_0000-S23-P3_5  efficientdet-d5     0.5     eager    sort   \n",
       "4        training_0000-S23-P4_5  efficientdet-d5     0.5     eager    sort   \n",
       "...                         ...              ...     ...       ...     ...   \n",
       "1704955   training_0003-S1-P0_5  efficientdet-d6     0.3     eager    sort   \n",
       "1704956   training_0003-S1-P1_5  efficientdet-d6     0.3     eager    sort   \n",
       "1704957   training_0003-S1-P2_5  efficientdet-d6     0.3     eager    sort   \n",
       "1704958   training_0003-S1-P3_5  efficientdet-d6     0.3     eager    sort   \n",
       "1704959   training_0003-S1-P4_5  efficientdet-d6     0.3     eager    sort   \n",
       "\n",
       "         T-min-iou  T-max-age  T-every-nth-det      score  \n",
       "0              0.3          5                1  30.547550  \n",
       "1              0.3          5                1  39.197930  \n",
       "2              0.3          5                1  37.049861  \n",
       "3              0.3          5                1  28.266494  \n",
       "4              0.3          5                1  29.371688  \n",
       "...            ...        ...              ...        ...  \n",
       "1704955        0.5          3                3  -9.959350  \n",
       "1704956        0.5          3                3  -3.034682  \n",
       "1704957        0.5          3                3 -10.264901  \n",
       "1704958        0.5          3                3 -27.734375  \n",
       "1704959        0.5          3                3 -45.783133  \n",
       "\n",
       "[1704960 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_df = config_df[config_df[\"D-seq-pol\"] != \"infinite\"]  # filter out infinite runs\n",
    "config_df[\"D-conf\"] = config_df[\"D-conf\"].astype(float)\n",
    "config_df[\"T-min-iou\"] = config_df[\"T-min-iou\"].astype(float)\n",
    "config_df[\"T-max-age\"] = config_df[\"T-max-age\"].astype(int)\n",
    "config_df[\"T-every-nth-det\"] = config_df[\"T-every-nth-det\"].astype(int)\n",
    "config_df = config_df.drop(columns=[\"metric\"])\n",
    "config_df[\"score\"] = config_df[\"score\"].astype(float)\n",
    "config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"oracle_k_10_policy.pl\", 'rb') as f:\n",
    "    oracle_k_10_policy = pickle.load(f)\n",
    "import json\n",
    "oracle_k_10_configs = [json.loads(s) for s in np.unique([json.dumps(c) for c in oracle_k_10_policy.values()])]\n",
    "len(oracle_k_10_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:11<00:00,  4.49it/s]\n"
     ]
    }
   ],
   "source": [
    "config_df = pd.concat([get_rows(config_df, c) for c in tqdm(oracle_k_10_configs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>avg_bbox_longevity</th>\n",
       "      <th>90p_bbox_longevity</th>\n",
       "      <th>90p_num_bboxes</th>\n",
       "      <th>90p_bbox_speed</th>\n",
       "      <th>90p_bbox_size</th>\n",
       "      <th>avg_num_bboxes</th>\n",
       "      <th>avg_bbox_speed</th>\n",
       "      <th>avg_bbox_size</th>\n",
       "      <th>avg_ego_speed</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>weather</th>\n",
       "      <th>location</th>\n",
       "      <th>scenario_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.656465</td>\n",
       "      <td>4230.876055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.791686</td>\n",
       "      <td>2307.979946</td>\n",
       "      <td>9.839008</td>\n",
       "      <td>Day</td>\n",
       "      <td>sunny</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S_24-P0_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.158862</td>\n",
       "      <td>11963.348346</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>21.910720</td>\n",
       "      <td>2870.257797</td>\n",
       "      <td>9.867627</td>\n",
       "      <td>Day</td>\n",
       "      <td>sunny</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S_24-P1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>203.228819</td>\n",
       "      <td>3270.956020</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>47.303100</td>\n",
       "      <td>952.989819</td>\n",
       "      <td>9.172085</td>\n",
       "      <td>Day</td>\n",
       "      <td>sunny</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S_24-P2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>280.682187</td>\n",
       "      <td>20169.298040</td>\n",
       "      <td>5.525000</td>\n",
       "      <td>220.192392</td>\n",
       "      <td>8177.688289</td>\n",
       "      <td>8.852530</td>\n",
       "      <td>Day</td>\n",
       "      <td>sunny</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S_24-P3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25.428571</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>209.327258</td>\n",
       "      <td>3387.636791</td>\n",
       "      <td>4.564103</td>\n",
       "      <td>170.470484</td>\n",
       "      <td>2728.638435</td>\n",
       "      <td>6.345968</td>\n",
       "      <td>Day</td>\n",
       "      <td>sunny</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S_24-P4_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1222</td>\n",
       "      <td>25.140000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.665209</td>\n",
       "      <td>873.811803</td>\n",
       "      <td>31.425000</td>\n",
       "      <td>40.964967</td>\n",
       "      <td>613.666850</td>\n",
       "      <td>20.180857</td>\n",
       "      <td>Day</td>\n",
       "      <td>sunny</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S_23-P0_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1223</td>\n",
       "      <td>21.102041</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>47.115496</td>\n",
       "      <td>1784.374827</td>\n",
       "      <td>25.850000</td>\n",
       "      <td>37.469432</td>\n",
       "      <td>1222.445215</td>\n",
       "      <td>19.504756</td>\n",
       "      <td>Day</td>\n",
       "      <td>sunny</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S_23-P1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1224</td>\n",
       "      <td>27.405405</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>53.371373</td>\n",
       "      <td>2593.207268</td>\n",
       "      <td>25.350000</td>\n",
       "      <td>46.546113</td>\n",
       "      <td>2069.365273</td>\n",
       "      <td>14.931406</td>\n",
       "      <td>Day</td>\n",
       "      <td>sunny</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S_23-P2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1225</td>\n",
       "      <td>29.921053</td>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>66.133055</td>\n",
       "      <td>6546.779569</td>\n",
       "      <td>28.425000</td>\n",
       "      <td>48.762617</td>\n",
       "      <td>4481.260176</td>\n",
       "      <td>8.980759</td>\n",
       "      <td>Day</td>\n",
       "      <td>sunny</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S_23-P3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>1226</td>\n",
       "      <td>26.571429</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>52.514593</td>\n",
       "      <td>17933.863551</td>\n",
       "      <td>24.473684</td>\n",
       "      <td>34.686690</td>\n",
       "      <td>11744.313426</td>\n",
       "      <td>3.629046</td>\n",
       "      <td>Day</td>\n",
       "      <td>sunny</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S_23-P4_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1227 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  avg_bbox_longevity  90p_bbox_longevity  90p_num_bboxes  \\\n",
       "0              0           40.000000                40.0             1.0   \n",
       "1              1           12.000000                12.0             1.0   \n",
       "2              2            6.000000                11.0             3.0   \n",
       "3              3           36.833333                40.0             6.0   \n",
       "4              4           25.428571                39.0             6.0   \n",
       "...          ...                 ...                 ...             ...   \n",
       "1222        1222           25.140000                40.0            35.0   \n",
       "1223        1223           21.102041                40.0            28.0   \n",
       "1224        1224           27.405405                40.0            28.0   \n",
       "1225        1225           29.921053                40.0            31.0   \n",
       "1226        1226           26.571429                38.0            28.3   \n",
       "\n",
       "      90p_bbox_speed  90p_bbox_size  avg_num_bboxes  avg_bbox_speed  \\\n",
       "0          85.656465    4230.876055        1.000000       59.791686   \n",
       "1         108.158862   11963.348346        0.300000       21.910720   \n",
       "2         203.228819    3270.956020        0.750000       47.303100   \n",
       "3         280.682187   20169.298040        5.525000      220.192392   \n",
       "4         209.327258    3387.636791        4.564103      170.470484   \n",
       "...              ...            ...             ...             ...   \n",
       "1222       49.665209     873.811803       31.425000       40.964967   \n",
       "1223       47.115496    1784.374827       25.850000       37.469432   \n",
       "1224       53.371373    2593.207268       25.350000       46.546113   \n",
       "1225       66.133055    6546.779569       28.425000       48.762617   \n",
       "1226       52.514593   17933.863551       24.473684       34.686690   \n",
       "\n",
       "      avg_bbox_size  avg_ego_speed time_of_day weather      location  \\\n",
       "0       2307.979946       9.839008         Day   sunny   location_sf   \n",
       "1       2870.257797       9.867627         Day   sunny   location_sf   \n",
       "2        952.989819       9.172085         Day   sunny   location_sf   \n",
       "3       8177.688289       8.852530         Day   sunny   location_sf   \n",
       "4       2728.638435       6.345968         Day   sunny   location_sf   \n",
       "...             ...            ...         ...     ...           ...   \n",
       "1222     613.666850      20.180857         Day   sunny  location_phx   \n",
       "1223    1222.445215      19.504756         Day   sunny  location_phx   \n",
       "1224    2069.365273      14.931406         Day   sunny  location_phx   \n",
       "1225    4481.260176       8.980759         Day   sunny  location_phx   \n",
       "1226   11744.313426       3.629046         Day   sunny  location_phx   \n",
       "\n",
       "                scenario_name  \n",
       "0     training_0004-S_24-P0_5  \n",
       "1     training_0004-S_24-P1_5  \n",
       "2     training_0004-S_24-P2_5  \n",
       "3     training_0004-S_24-P3_5  \n",
       "4     training_0004-S_24-P4_5  \n",
       "...                       ...  \n",
       "1222  training_0006-S_23-P0_5  \n",
       "1223  training_0006-S_23-P1_5  \n",
       "1224  training_0006-S_23-P2_5  \n",
       "1225  training_0006-S_23-P3_5  \n",
       "1226  training_0006-S_23-P4_5  \n",
       "\n",
       "[1227 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_feats_df = pd.read_csv(\"../data/scenario_features_v3_fine_4s.csv\")\n",
    "scenario_feats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'avg_bbox_longevity', '90p_bbox_longevity',\n",
       "       '90p_num_bboxes', '90p_bbox_speed', '90p_bbox_size', 'avg_num_bboxes',\n",
       "       'avg_bbox_speed', 'avg_bbox_size', 'avg_ego_speed', 'time_of_day',\n",
       "       'weather', 'location', 'scenario_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_feats_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_bbox_longevity</th>\n",
       "      <th>90p_bbox_longevity</th>\n",
       "      <th>90p_num_bboxes</th>\n",
       "      <th>90p_bbox_speed</th>\n",
       "      <th>90p_bbox_size</th>\n",
       "      <th>avg_num_bboxes</th>\n",
       "      <th>avg_bbox_speed</th>\n",
       "      <th>avg_bbox_size</th>\n",
       "      <th>avg_ego_speed</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>location</th>\n",
       "      <th>scenario_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.656465</td>\n",
       "      <td>4230.876055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.791686</td>\n",
       "      <td>2307.979946</td>\n",
       "      <td>9.839008</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S24-P0_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.158862</td>\n",
       "      <td>11963.348346</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>21.910720</td>\n",
       "      <td>2870.257797</td>\n",
       "      <td>9.867627</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S24-P1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>203.228819</td>\n",
       "      <td>3270.956020</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>47.303100</td>\n",
       "      <td>952.989819</td>\n",
       "      <td>9.172085</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S24-P2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.833333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>280.682187</td>\n",
       "      <td>20169.298040</td>\n",
       "      <td>5.525000</td>\n",
       "      <td>220.192392</td>\n",
       "      <td>8177.688289</td>\n",
       "      <td>8.852530</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S24-P3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.428571</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>209.327258</td>\n",
       "      <td>3387.636791</td>\n",
       "      <td>4.564103</td>\n",
       "      <td>170.470484</td>\n",
       "      <td>2728.638435</td>\n",
       "      <td>6.345968</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S24-P4_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>25.140000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.665209</td>\n",
       "      <td>873.811803</td>\n",
       "      <td>31.425000</td>\n",
       "      <td>40.964967</td>\n",
       "      <td>613.666850</td>\n",
       "      <td>20.180857</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S23-P0_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>21.102041</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>47.115496</td>\n",
       "      <td>1784.374827</td>\n",
       "      <td>25.850000</td>\n",
       "      <td>37.469432</td>\n",
       "      <td>1222.445215</td>\n",
       "      <td>19.504756</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S23-P1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>27.405405</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>53.371373</td>\n",
       "      <td>2593.207268</td>\n",
       "      <td>25.350000</td>\n",
       "      <td>46.546113</td>\n",
       "      <td>2069.365273</td>\n",
       "      <td>14.931406</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S23-P2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>29.921053</td>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>66.133055</td>\n",
       "      <td>6546.779569</td>\n",
       "      <td>28.425000</td>\n",
       "      <td>48.762617</td>\n",
       "      <td>4481.260176</td>\n",
       "      <td>8.980759</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S23-P3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>26.571429</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>52.514593</td>\n",
       "      <td>17933.863551</td>\n",
       "      <td>24.473684</td>\n",
       "      <td>34.686690</td>\n",
       "      <td>11744.313426</td>\n",
       "      <td>3.629046</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S23-P4_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1227 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_bbox_longevity  90p_bbox_longevity  90p_num_bboxes  90p_bbox_speed  \\\n",
       "0              40.000000                40.0             1.0       85.656465   \n",
       "1              12.000000                12.0             1.0      108.158862   \n",
       "2               6.000000                11.0             3.0      203.228819   \n",
       "3              36.833333                40.0             6.0      280.682187   \n",
       "4              25.428571                39.0             6.0      209.327258   \n",
       "...                  ...                 ...             ...             ...   \n",
       "1222           25.140000                40.0            35.0       49.665209   \n",
       "1223           21.102041                40.0            28.0       47.115496   \n",
       "1224           27.405405                40.0            28.0       53.371373   \n",
       "1225           29.921053                40.0            31.0       66.133055   \n",
       "1226           26.571429                38.0            28.3       52.514593   \n",
       "\n",
       "      90p_bbox_size  avg_num_bboxes  avg_bbox_speed  avg_bbox_size  \\\n",
       "0       4230.876055        1.000000       59.791686    2307.979946   \n",
       "1      11963.348346        0.300000       21.910720    2870.257797   \n",
       "2       3270.956020        0.750000       47.303100     952.989819   \n",
       "3      20169.298040        5.525000      220.192392    8177.688289   \n",
       "4       3387.636791        4.564103      170.470484    2728.638435   \n",
       "...             ...             ...             ...            ...   \n",
       "1222     873.811803       31.425000       40.964967     613.666850   \n",
       "1223    1784.374827       25.850000       37.469432    1222.445215   \n",
       "1224    2593.207268       25.350000       46.546113    2069.365273   \n",
       "1225    6546.779569       28.425000       48.762617    4481.260176   \n",
       "1226   17933.863551       24.473684       34.686690   11744.313426   \n",
       "\n",
       "      avg_ego_speed time_of_day      location           scenario_name  \n",
       "0          9.839008         Day   location_sf  training_0004-S24-P0_5  \n",
       "1          9.867627         Day   location_sf  training_0004-S24-P1_5  \n",
       "2          9.172085         Day   location_sf  training_0004-S24-P2_5  \n",
       "3          8.852530         Day   location_sf  training_0004-S24-P3_5  \n",
       "4          6.345968         Day   location_sf  training_0004-S24-P4_5  \n",
       "...             ...         ...           ...                     ...  \n",
       "1222      20.180857         Day  location_phx  training_0006-S23-P0_5  \n",
       "1223      19.504756         Day  location_phx  training_0006-S23-P1_5  \n",
       "1224      14.931406         Day  location_phx  training_0006-S23-P2_5  \n",
       "1225       8.980759         Day  location_phx  training_0006-S23-P3_5  \n",
       "1226       3.629046         Day  location_phx  training_0006-S23-P4_5  \n",
       "\n",
       "[1227 rows x 12 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_feats_df = scenario_feats_df.loc[:, ~scenario_feats_df.columns.str.contains('^Unnamed')]\n",
    "scenario_feats_df = scenario_feats_df.drop(columns=[\"weather\"])  # weather column is all the same\n",
    "scenario_feats_df[\"scenario_name\"] = scenario_feats_df[\"scenario_name\"].apply(lambda x: x.replace(\"-S_\", \"-S\"))\n",
    "scenario_feats_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from functools import reduce\n",
    "scenario_feats_df = scenario_feats_df[\n",
    "    reduce(lambda x, y: x&y, [~scenario_feats_df[\"scenario_name\"].str.contains(\"training_000{}\".format(x)) for x in [6, 7, 8, 9]])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_bbox_longevity</th>\n",
       "      <th>90p_bbox_longevity</th>\n",
       "      <th>90p_num_bboxes</th>\n",
       "      <th>90p_bbox_speed</th>\n",
       "      <th>90p_bbox_size</th>\n",
       "      <th>avg_num_bboxes</th>\n",
       "      <th>avg_bbox_speed</th>\n",
       "      <th>avg_bbox_size</th>\n",
       "      <th>avg_ego_speed</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>location</th>\n",
       "      <th>scenario_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.656465</td>\n",
       "      <td>4230.876055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.791686</td>\n",
       "      <td>2307.979946</td>\n",
       "      <td>9.839008</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S24-P0_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.158862</td>\n",
       "      <td>11963.348346</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>21.910720</td>\n",
       "      <td>2870.257797</td>\n",
       "      <td>9.867627</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S24-P1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>203.228819</td>\n",
       "      <td>3270.956020</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>47.303100</td>\n",
       "      <td>952.989819</td>\n",
       "      <td>9.172085</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S24-P2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.833333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>280.682187</td>\n",
       "      <td>20169.298040</td>\n",
       "      <td>5.525000</td>\n",
       "      <td>220.192392</td>\n",
       "      <td>8177.688289</td>\n",
       "      <td>8.852530</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S24-P3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.428571</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>209.327258</td>\n",
       "      <td>3387.636791</td>\n",
       "      <td>4.564103</td>\n",
       "      <td>170.470484</td>\n",
       "      <td>2728.638435</td>\n",
       "      <td>6.345968</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>training_0004-S24-P4_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>25.140000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.665209</td>\n",
       "      <td>873.811803</td>\n",
       "      <td>31.425000</td>\n",
       "      <td>40.964967</td>\n",
       "      <td>613.666850</td>\n",
       "      <td>20.180857</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S23-P0_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>21.102041</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>47.115496</td>\n",
       "      <td>1784.374827</td>\n",
       "      <td>25.850000</td>\n",
       "      <td>37.469432</td>\n",
       "      <td>1222.445215</td>\n",
       "      <td>19.504756</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S23-P1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>27.405405</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>53.371373</td>\n",
       "      <td>2593.207268</td>\n",
       "      <td>25.350000</td>\n",
       "      <td>46.546113</td>\n",
       "      <td>2069.365273</td>\n",
       "      <td>14.931406</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S23-P2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>29.921053</td>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>66.133055</td>\n",
       "      <td>6546.779569</td>\n",
       "      <td>28.425000</td>\n",
       "      <td>48.762617</td>\n",
       "      <td>4481.260176</td>\n",
       "      <td>8.980759</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S23-P3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>26.571429</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>52.514593</td>\n",
       "      <td>17933.863551</td>\n",
       "      <td>24.473684</td>\n",
       "      <td>34.686690</td>\n",
       "      <td>11744.313426</td>\n",
       "      <td>3.629046</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>training_0006-S23-P4_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1227 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_bbox_longevity  90p_bbox_longevity  90p_num_bboxes  90p_bbox_speed  \\\n",
       "0              40.000000                40.0             1.0       85.656465   \n",
       "1              12.000000                12.0             1.0      108.158862   \n",
       "2               6.000000                11.0             3.0      203.228819   \n",
       "3              36.833333                40.0             6.0      280.682187   \n",
       "4              25.428571                39.0             6.0      209.327258   \n",
       "...                  ...                 ...             ...             ...   \n",
       "1222           25.140000                40.0            35.0       49.665209   \n",
       "1223           21.102041                40.0            28.0       47.115496   \n",
       "1224           27.405405                40.0            28.0       53.371373   \n",
       "1225           29.921053                40.0            31.0       66.133055   \n",
       "1226           26.571429                38.0            28.3       52.514593   \n",
       "\n",
       "      90p_bbox_size  avg_num_bboxes  avg_bbox_speed  avg_bbox_size  \\\n",
       "0       4230.876055        1.000000       59.791686    2307.979946   \n",
       "1      11963.348346        0.300000       21.910720    2870.257797   \n",
       "2       3270.956020        0.750000       47.303100     952.989819   \n",
       "3      20169.298040        5.525000      220.192392    8177.688289   \n",
       "4       3387.636791        4.564103      170.470484    2728.638435   \n",
       "...             ...             ...             ...            ...   \n",
       "1222     873.811803       31.425000       40.964967     613.666850   \n",
       "1223    1784.374827       25.850000       37.469432    1222.445215   \n",
       "1224    2593.207268       25.350000       46.546113    2069.365273   \n",
       "1225    6546.779569       28.425000       48.762617    4481.260176   \n",
       "1226   17933.863551       24.473684       34.686690   11744.313426   \n",
       "\n",
       "      avg_ego_speed time_of_day      location           scenario_name  \n",
       "0          9.839008         Day   location_sf  training_0004-S24-P0_5  \n",
       "1          9.867627         Day   location_sf  training_0004-S24-P1_5  \n",
       "2          9.172085         Day   location_sf  training_0004-S24-P2_5  \n",
       "3          8.852530         Day   location_sf  training_0004-S24-P3_5  \n",
       "4          6.345968         Day   location_sf  training_0004-S24-P4_5  \n",
       "...             ...         ...           ...                     ...  \n",
       "1222      20.180857         Day  location_phx  training_0006-S23-P0_5  \n",
       "1223      19.504756         Day  location_phx  training_0006-S23-P1_5  \n",
       "1224      14.931406         Day  location_phx  training_0006-S23-P2_5  \n",
       "1225       8.980759         Day  location_phx  training_0006-S23-P3_5  \n",
       "1226       3.629046         Day  location_phx  training_0006-S23-P4_5  \n",
       "\n",
       "[1227 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_feats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join tables, one-hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'training_0001-S15-P2_5',\n",
       "  'training_0001-S3-P4_5',\n",
       "  'training_0002-S21-P3_5',\n",
       "  'training_0004-S7-P2_5',\n",
       "  'training_0004-S7-P3_5',\n",
       "  'training_0005-S20-P0_5',\n",
       "  'training_0005-S20-P1_5',\n",
       "  'training_0005-S20-P4_5',\n",
       "  'training_0005-S23-P0_5',\n",
       "  'training_0005-S4-P3_5',\n",
       "  'training_0005-S4-P4_5'},\n",
       " {'training_0006-S0-P0_5',\n",
       "  'training_0006-S0-P1_5',\n",
       "  'training_0006-S0-P2_5',\n",
       "  'training_0006-S0-P3_5',\n",
       "  'training_0006-S0-P4_5',\n",
       "  'training_0006-S1-P0_5',\n",
       "  'training_0006-S1-P1_5',\n",
       "  'training_0006-S1-P2_5',\n",
       "  'training_0006-S1-P3_5',\n",
       "  'training_0006-S1-P4_5',\n",
       "  'training_0006-S10-P0_5',\n",
       "  'training_0006-S10-P1_5',\n",
       "  'training_0006-S10-P2_5',\n",
       "  'training_0006-S10-P3_5',\n",
       "  'training_0006-S10-P4_5',\n",
       "  'training_0006-S11-P0_5',\n",
       "  'training_0006-S11-P1_5',\n",
       "  'training_0006-S11-P2_5',\n",
       "  'training_0006-S11-P3_5',\n",
       "  'training_0006-S11-P4_5',\n",
       "  'training_0006-S12-P0_5',\n",
       "  'training_0006-S12-P1_5',\n",
       "  'training_0006-S12-P2_5',\n",
       "  'training_0006-S12-P3_5',\n",
       "  'training_0006-S12-P4_5',\n",
       "  'training_0006-S13-P0_5',\n",
       "  'training_0006-S13-P1_5',\n",
       "  'training_0006-S13-P2_5',\n",
       "  'training_0006-S13-P3_5',\n",
       "  'training_0006-S13-P4_5',\n",
       "  'training_0006-S14-P0_5',\n",
       "  'training_0006-S14-P1_5',\n",
       "  'training_0006-S14-P2_5',\n",
       "  'training_0006-S14-P3_5',\n",
       "  'training_0006-S14-P4_5',\n",
       "  'training_0006-S15-P0_5',\n",
       "  'training_0006-S15-P1_5',\n",
       "  'training_0006-S15-P2_5',\n",
       "  'training_0006-S15-P3_5',\n",
       "  'training_0006-S15-P4_5',\n",
       "  'training_0006-S16-P0_5',\n",
       "  'training_0006-S16-P1_5',\n",
       "  'training_0006-S16-P2_5',\n",
       "  'training_0006-S16-P3_5',\n",
       "  'training_0006-S16-P4_5',\n",
       "  'training_0006-S17-P0_5',\n",
       "  'training_0006-S17-P1_5',\n",
       "  'training_0006-S17-P2_5',\n",
       "  'training_0006-S17-P3_5',\n",
       "  'training_0006-S17-P4_5',\n",
       "  'training_0006-S18-P0_5',\n",
       "  'training_0006-S18-P1_5',\n",
       "  'training_0006-S18-P2_5',\n",
       "  'training_0006-S18-P3_5',\n",
       "  'training_0006-S18-P4_5',\n",
       "  'training_0006-S19-P0_5',\n",
       "  'training_0006-S19-P1_5',\n",
       "  'training_0006-S19-P2_5',\n",
       "  'training_0006-S19-P3_5',\n",
       "  'training_0006-S19-P4_5',\n",
       "  'training_0006-S2-P0_5',\n",
       "  'training_0006-S2-P1_5',\n",
       "  'training_0006-S2-P2_5',\n",
       "  'training_0006-S2-P3_5',\n",
       "  'training_0006-S2-P4_5',\n",
       "  'training_0006-S20-P0_5',\n",
       "  'training_0006-S20-P1_5',\n",
       "  'training_0006-S20-P2_5',\n",
       "  'training_0006-S20-P3_5',\n",
       "  'training_0006-S20-P4_5',\n",
       "  'training_0006-S21-P0_5',\n",
       "  'training_0006-S21-P1_5',\n",
       "  'training_0006-S21-P2_5',\n",
       "  'training_0006-S21-P3_5',\n",
       "  'training_0006-S21-P4_5',\n",
       "  'training_0006-S22-P0_5',\n",
       "  'training_0006-S22-P1_5',\n",
       "  'training_0006-S22-P2_5',\n",
       "  'training_0006-S22-P3_5',\n",
       "  'training_0006-S22-P4_5',\n",
       "  'training_0006-S23-P0_5',\n",
       "  'training_0006-S23-P1_5',\n",
       "  'training_0006-S23-P2_5',\n",
       "  'training_0006-S23-P3_5',\n",
       "  'training_0006-S23-P4_5',\n",
       "  'training_0006-S24-P0_5',\n",
       "  'training_0006-S24-P1_5',\n",
       "  'training_0006-S24-P2_5',\n",
       "  'training_0006-S24-P3_5',\n",
       "  'training_0006-S24-P4_5',\n",
       "  'training_0006-S3-P0_5',\n",
       "  'training_0006-S3-P1_5',\n",
       "  'training_0006-S3-P2_5',\n",
       "  'training_0006-S3-P3_5',\n",
       "  'training_0006-S3-P4_5',\n",
       "  'training_0006-S4-P0_5',\n",
       "  'training_0006-S4-P1_5',\n",
       "  'training_0006-S4-P2_5',\n",
       "  'training_0006-S4-P3_5',\n",
       "  'training_0006-S4-P4_5',\n",
       "  'training_0006-S5-P0_5',\n",
       "  'training_0006-S5-P1_5',\n",
       "  'training_0006-S5-P2_5',\n",
       "  'training_0006-S5-P3_5',\n",
       "  'training_0006-S5-P4_5',\n",
       "  'training_0006-S6-P0_5',\n",
       "  'training_0006-S6-P1_5',\n",
       "  'training_0006-S6-P2_5',\n",
       "  'training_0006-S6-P3_5',\n",
       "  'training_0006-S6-P4_5',\n",
       "  'training_0006-S7-P0_5',\n",
       "  'training_0006-S7-P1_5',\n",
       "  'training_0006-S7-P2_5',\n",
       "  'training_0006-S7-P3_5',\n",
       "  'training_0006-S7-P4_5',\n",
       "  'training_0006-S8-P0_5',\n",
       "  'training_0006-S8-P1_5',\n",
       "  'training_0006-S8-P2_5',\n",
       "  'training_0006-S8-P3_5',\n",
       "  'training_0006-S8-P4_5',\n",
       "  'training_0006-S9-P0_5',\n",
       "  'training_0006-S9-P1_5',\n",
       "  'training_0006-S9-P2_5',\n",
       "  'training_0006-S9-P3_5',\n",
       "  'training_0006-S9-P4_5',\n",
       "  'training_0007-S0-P0_5',\n",
       "  'training_0007-S0-P1_5',\n",
       "  'training_0007-S0-P2_5',\n",
       "  'training_0007-S0-P3_5',\n",
       "  'training_0007-S0-P4_5',\n",
       "  'training_0007-S1-P0_5',\n",
       "  'training_0007-S1-P1_5',\n",
       "  'training_0007-S1-P2_5',\n",
       "  'training_0007-S1-P3_5',\n",
       "  'training_0007-S1-P4_5',\n",
       "  'training_0007-S10-P0_5',\n",
       "  'training_0007-S10-P1_5',\n",
       "  'training_0007-S10-P2_5',\n",
       "  'training_0007-S10-P3_5',\n",
       "  'training_0007-S10-P4_5',\n",
       "  'training_0007-S11-P0_5',\n",
       "  'training_0007-S11-P1_5',\n",
       "  'training_0007-S11-P2_5',\n",
       "  'training_0007-S11-P3_5',\n",
       "  'training_0007-S11-P4_5',\n",
       "  'training_0007-S12-P0_5',\n",
       "  'training_0007-S12-P1_5',\n",
       "  'training_0007-S12-P2_5',\n",
       "  'training_0007-S12-P3_5',\n",
       "  'training_0007-S12-P4_5',\n",
       "  'training_0007-S13-P0_5',\n",
       "  'training_0007-S13-P1_5',\n",
       "  'training_0007-S13-P2_5',\n",
       "  'training_0007-S13-P3_5',\n",
       "  'training_0007-S13-P4_5',\n",
       "  'training_0007-S14-P0_5',\n",
       "  'training_0007-S14-P1_5',\n",
       "  'training_0007-S14-P2_5',\n",
       "  'training_0007-S14-P3_5',\n",
       "  'training_0007-S14-P4_5',\n",
       "  'training_0007-S15-P0_5',\n",
       "  'training_0007-S15-P1_5',\n",
       "  'training_0007-S15-P2_5',\n",
       "  'training_0007-S15-P3_5',\n",
       "  'training_0007-S15-P4_5',\n",
       "  'training_0007-S16-P0_5',\n",
       "  'training_0007-S16-P1_5',\n",
       "  'training_0007-S16-P2_5',\n",
       "  'training_0007-S16-P3_5',\n",
       "  'training_0007-S16-P4_5',\n",
       "  'training_0007-S17-P0_5',\n",
       "  'training_0007-S17-P1_5',\n",
       "  'training_0007-S17-P2_5',\n",
       "  'training_0007-S17-P3_5',\n",
       "  'training_0007-S17-P4_5',\n",
       "  'training_0007-S18-P0_5',\n",
       "  'training_0007-S18-P1_5',\n",
       "  'training_0007-S18-P2_5',\n",
       "  'training_0007-S18-P3_5',\n",
       "  'training_0007-S18-P4_5',\n",
       "  'training_0007-S19-P0_5',\n",
       "  'training_0007-S19-P1_5',\n",
       "  'training_0007-S19-P2_5',\n",
       "  'training_0007-S19-P3_5',\n",
       "  'training_0007-S19-P4_5',\n",
       "  'training_0007-S2-P0_5',\n",
       "  'training_0007-S2-P1_5',\n",
       "  'training_0007-S2-P2_5',\n",
       "  'training_0007-S2-P3_5',\n",
       "  'training_0007-S2-P4_5',\n",
       "  'training_0007-S20-P0_5',\n",
       "  'training_0007-S20-P1_5',\n",
       "  'training_0007-S20-P2_5',\n",
       "  'training_0007-S20-P3_5',\n",
       "  'training_0007-S20-P4_5',\n",
       "  'training_0007-S21-P0_5',\n",
       "  'training_0007-S21-P1_5',\n",
       "  'training_0007-S21-P2_5',\n",
       "  'training_0007-S21-P3_5',\n",
       "  'training_0007-S21-P4_5',\n",
       "  'training_0007-S22-P0_5',\n",
       "  'training_0007-S22-P1_5',\n",
       "  'training_0007-S22-P2_5',\n",
       "  'training_0007-S22-P3_5',\n",
       "  'training_0007-S22-P4_5',\n",
       "  'training_0007-S23-P0_5',\n",
       "  'training_0007-S23-P1_5',\n",
       "  'training_0007-S23-P2_5',\n",
       "  'training_0007-S23-P3_5',\n",
       "  'training_0007-S23-P4_5',\n",
       "  'training_0007-S24-P0_5',\n",
       "  'training_0007-S24-P1_5',\n",
       "  'training_0007-S24-P2_5',\n",
       "  'training_0007-S24-P3_5',\n",
       "  'training_0007-S24-P4_5',\n",
       "  'training_0007-S3-P0_5',\n",
       "  'training_0007-S3-P1_5',\n",
       "  'training_0007-S3-P2_5',\n",
       "  'training_0007-S3-P3_5',\n",
       "  'training_0007-S3-P4_5',\n",
       "  'training_0007-S4-P0_5',\n",
       "  'training_0007-S4-P1_5',\n",
       "  'training_0007-S4-P2_5',\n",
       "  'training_0007-S4-P3_5',\n",
       "  'training_0007-S4-P4_5',\n",
       "  'training_0007-S5-P0_5',\n",
       "  'training_0007-S5-P1_5',\n",
       "  'training_0007-S5-P2_5',\n",
       "  'training_0007-S5-P3_5',\n",
       "  'training_0007-S5-P4_5',\n",
       "  'training_0007-S6-P0_5',\n",
       "  'training_0007-S6-P1_5',\n",
       "  'training_0007-S6-P2_5',\n",
       "  'training_0007-S6-P3_5',\n",
       "  'training_0007-S6-P4_5',\n",
       "  'training_0007-S7-P0_5',\n",
       "  'training_0007-S7-P1_5',\n",
       "  'training_0007-S7-P2_5',\n",
       "  'training_0007-S7-P3_5',\n",
       "  'training_0007-S7-P4_5',\n",
       "  'training_0007-S8-P0_5',\n",
       "  'training_0007-S8-P1_5',\n",
       "  'training_0007-S8-P2_5',\n",
       "  'training_0007-S8-P3_5',\n",
       "  'training_0007-S8-P4_5',\n",
       "  'training_0007-S9-P0_5',\n",
       "  'training_0007-S9-P1_5',\n",
       "  'training_0007-S9-P2_5',\n",
       "  'training_0007-S9-P3_5',\n",
       "  'training_0007-S9-P4_5',\n",
       "  'training_0008-S0-P0_5',\n",
       "  'training_0008-S0-P1_5',\n",
       "  'training_0008-S0-P2_5',\n",
       "  'training_0008-S0-P3_5',\n",
       "  'training_0008-S0-P4_5',\n",
       "  'training_0008-S1-P0_5',\n",
       "  'training_0008-S1-P1_5',\n",
       "  'training_0008-S1-P2_5',\n",
       "  'training_0008-S1-P3_5',\n",
       "  'training_0008-S1-P4_5',\n",
       "  'training_0008-S10-P0_5',\n",
       "  'training_0008-S10-P1_5',\n",
       "  'training_0008-S10-P2_5',\n",
       "  'training_0008-S10-P3_5',\n",
       "  'training_0008-S10-P4_5',\n",
       "  'training_0008-S11-P0_5',\n",
       "  'training_0008-S11-P1_5',\n",
       "  'training_0008-S11-P2_5',\n",
       "  'training_0008-S11-P3_5',\n",
       "  'training_0008-S11-P4_5',\n",
       "  'training_0008-S12-P0_5',\n",
       "  'training_0008-S12-P1_5',\n",
       "  'training_0008-S12-P2_5',\n",
       "  'training_0008-S12-P3_5',\n",
       "  'training_0008-S12-P4_5',\n",
       "  'training_0008-S13-P0_5',\n",
       "  'training_0008-S13-P1_5',\n",
       "  'training_0008-S13-P2_5',\n",
       "  'training_0008-S13-P3_5',\n",
       "  'training_0008-S13-P4_5',\n",
       "  'training_0008-S14-P0_5',\n",
       "  'training_0008-S14-P1_5',\n",
       "  'training_0008-S14-P2_5',\n",
       "  'training_0008-S14-P3_5',\n",
       "  'training_0008-S14-P4_5',\n",
       "  'training_0008-S15-P0_5',\n",
       "  'training_0008-S15-P1_5',\n",
       "  'training_0008-S15-P2_5',\n",
       "  'training_0008-S15-P3_5',\n",
       "  'training_0008-S15-P4_5',\n",
       "  'training_0008-S16-P0_5',\n",
       "  'training_0008-S16-P1_5',\n",
       "  'training_0008-S16-P2_5',\n",
       "  'training_0008-S16-P3_5',\n",
       "  'training_0008-S16-P4_5',\n",
       "  'training_0008-S17-P0_5',\n",
       "  'training_0008-S17-P1_5',\n",
       "  'training_0008-S17-P2_5',\n",
       "  'training_0008-S17-P3_5',\n",
       "  'training_0008-S17-P4_5',\n",
       "  'training_0008-S18-P0_5',\n",
       "  'training_0008-S18-P1_5',\n",
       "  'training_0008-S18-P2_5',\n",
       "  'training_0008-S18-P3_5',\n",
       "  'training_0008-S18-P4_5',\n",
       "  'training_0008-S19-P0_5',\n",
       "  'training_0008-S19-P1_5',\n",
       "  'training_0008-S19-P2_5',\n",
       "  'training_0008-S19-P3_5',\n",
       "  'training_0008-S19-P4_5',\n",
       "  'training_0008-S2-P0_5',\n",
       "  'training_0008-S2-P1_5',\n",
       "  'training_0008-S2-P2_5',\n",
       "  'training_0008-S2-P3_5',\n",
       "  'training_0008-S2-P4_5',\n",
       "  'training_0008-S20-P0_5',\n",
       "  'training_0008-S20-P1_5',\n",
       "  'training_0008-S20-P2_5',\n",
       "  'training_0008-S20-P3_5',\n",
       "  'training_0008-S20-P4_5',\n",
       "  'training_0008-S21-P0_5',\n",
       "  'training_0008-S21-P1_5',\n",
       "  'training_0008-S21-P2_5',\n",
       "  'training_0008-S21-P3_5',\n",
       "  'training_0008-S21-P4_5',\n",
       "  'training_0008-S22-P0_5',\n",
       "  'training_0008-S22-P1_5',\n",
       "  'training_0008-S22-P2_5',\n",
       "  'training_0008-S22-P3_5',\n",
       "  'training_0008-S22-P4_5',\n",
       "  'training_0008-S23-P0_5',\n",
       "  'training_0008-S23-P1_5',\n",
       "  'training_0008-S23-P2_5',\n",
       "  'training_0008-S23-P3_5',\n",
       "  'training_0008-S23-P4_5',\n",
       "  'training_0008-S24-P0_5',\n",
       "  'training_0008-S24-P1_5',\n",
       "  'training_0008-S24-P2_5',\n",
       "  'training_0008-S24-P3_5',\n",
       "  'training_0008-S24-P4_5',\n",
       "  'training_0008-S3-P0_5',\n",
       "  'training_0008-S3-P1_5',\n",
       "  'training_0008-S3-P2_5',\n",
       "  'training_0008-S3-P3_5',\n",
       "  'training_0008-S3-P4_5',\n",
       "  'training_0008-S4-P0_5',\n",
       "  'training_0008-S4-P1_5',\n",
       "  'training_0008-S4-P2_5',\n",
       "  'training_0008-S4-P3_5',\n",
       "  'training_0008-S4-P4_5',\n",
       "  'training_0008-S5-P0_5',\n",
       "  'training_0008-S5-P2_5',\n",
       "  'training_0008-S5-P3_5',\n",
       "  'training_0008-S5-P4_5',\n",
       "  'training_0008-S6-P0_5',\n",
       "  'training_0008-S6-P1_5',\n",
       "  'training_0008-S6-P2_5',\n",
       "  'training_0008-S6-P3_5',\n",
       "  'training_0008-S6-P4_5',\n",
       "  'training_0008-S7-P0_5',\n",
       "  'training_0008-S7-P1_5',\n",
       "  'training_0008-S7-P2_5',\n",
       "  'training_0008-S7-P3_5',\n",
       "  'training_0008-S7-P4_5',\n",
       "  'training_0008-S8-P0_5',\n",
       "  'training_0008-S8-P1_5',\n",
       "  'training_0008-S8-P2_5',\n",
       "  'training_0008-S8-P3_5',\n",
       "  'training_0008-S8-P4_5',\n",
       "  'training_0008-S9-P0_5',\n",
       "  'training_0008-S9-P1_5',\n",
       "  'training_0008-S9-P2_5',\n",
       "  'training_0008-S9-P3_5',\n",
       "  'training_0008-S9-P4_5',\n",
       "  'training_0009-S0-P0_5',\n",
       "  'training_0009-S0-P1_5',\n",
       "  'training_0009-S0-P2_5',\n",
       "  'training_0009-S0-P3_5',\n",
       "  'training_0009-S0-P4_5',\n",
       "  'training_0009-S1-P0_5',\n",
       "  'training_0009-S1-P1_5',\n",
       "  'training_0009-S1-P2_5',\n",
       "  'training_0009-S1-P3_5',\n",
       "  'training_0009-S1-P4_5',\n",
       "  'training_0009-S10-P0_5',\n",
       "  'training_0009-S10-P1_5',\n",
       "  'training_0009-S10-P3_5',\n",
       "  'training_0009-S10-P4_5',\n",
       "  'training_0009-S11-P0_5',\n",
       "  'training_0009-S11-P1_5',\n",
       "  'training_0009-S11-P2_5',\n",
       "  'training_0009-S11-P3_5',\n",
       "  'training_0009-S11-P4_5',\n",
       "  'training_0009-S12-P0_5',\n",
       "  'training_0009-S12-P1_5',\n",
       "  'training_0009-S12-P2_5',\n",
       "  'training_0009-S12-P3_5',\n",
       "  'training_0009-S12-P4_5',\n",
       "  'training_0009-S13-P0_5',\n",
       "  'training_0009-S13-P1_5',\n",
       "  'training_0009-S13-P2_5',\n",
       "  'training_0009-S13-P3_5',\n",
       "  'training_0009-S13-P4_5',\n",
       "  'training_0009-S14-P0_5',\n",
       "  'training_0009-S14-P1_5',\n",
       "  'training_0009-S14-P2_5',\n",
       "  'training_0009-S14-P3_5',\n",
       "  'training_0009-S14-P4_5',\n",
       "  'training_0009-S15-P0_5',\n",
       "  'training_0009-S15-P1_5',\n",
       "  'training_0009-S15-P2_5',\n",
       "  'training_0009-S15-P3_5',\n",
       "  'training_0009-S15-P4_5',\n",
       "  'training_0009-S16-P0_5',\n",
       "  'training_0009-S16-P1_5',\n",
       "  'training_0009-S16-P2_5',\n",
       "  'training_0009-S16-P3_5',\n",
       "  'training_0009-S16-P4_5',\n",
       "  'training_0009-S17-P0_5',\n",
       "  'training_0009-S17-P1_5',\n",
       "  'training_0009-S17-P2_5',\n",
       "  'training_0009-S17-P3_5',\n",
       "  'training_0009-S17-P4_5',\n",
       "  'training_0009-S18-P0_5',\n",
       "  'training_0009-S18-P1_5',\n",
       "  'training_0009-S18-P2_5',\n",
       "  'training_0009-S18-P3_5',\n",
       "  'training_0009-S18-P4_5',\n",
       "  'training_0009-S19-P0_5',\n",
       "  'training_0009-S19-P1_5',\n",
       "  'training_0009-S19-P2_5',\n",
       "  'training_0009-S19-P3_5',\n",
       "  'training_0009-S19-P4_5',\n",
       "  'training_0009-S2-P0_5',\n",
       "  'training_0009-S2-P1_5',\n",
       "  'training_0009-S2-P2_5',\n",
       "  'training_0009-S2-P3_5',\n",
       "  'training_0009-S2-P4_5',\n",
       "  'training_0009-S20-P0_5',\n",
       "  'training_0009-S20-P1_5',\n",
       "  'training_0009-S20-P2_5',\n",
       "  'training_0009-S20-P3_5',\n",
       "  'training_0009-S20-P4_5',\n",
       "  'training_0009-S21-P0_5',\n",
       "  'training_0009-S21-P1_5',\n",
       "  'training_0009-S21-P2_5',\n",
       "  'training_0009-S21-P3_5',\n",
       "  'training_0009-S21-P4_5',\n",
       "  'training_0009-S22-P0_5',\n",
       "  'training_0009-S22-P1_5',\n",
       "  'training_0009-S22-P2_5',\n",
       "  'training_0009-S22-P3_5',\n",
       "  'training_0009-S22-P4_5',\n",
       "  'training_0009-S23-P0_5',\n",
       "  'training_0009-S23-P1_5',\n",
       "  'training_0009-S23-P2_5',\n",
       "  'training_0009-S23-P3_5',\n",
       "  'training_0009-S23-P4_5',\n",
       "  'training_0009-S24-P0_5',\n",
       "  'training_0009-S24-P1_5',\n",
       "  'training_0009-S24-P2_5',\n",
       "  'training_0009-S24-P3_5',\n",
       "  'training_0009-S24-P4_5',\n",
       "  'training_0009-S3-P0_5',\n",
       "  'training_0009-S3-P1_5',\n",
       "  'training_0009-S3-P2_5',\n",
       "  'training_0009-S3-P3_5',\n",
       "  'training_0009-S3-P4_5',\n",
       "  'training_0009-S4-P0_5',\n",
       "  'training_0009-S4-P1_5',\n",
       "  'training_0009-S4-P2_5',\n",
       "  'training_0009-S4-P3_5',\n",
       "  'training_0009-S4-P4_5',\n",
       "  'training_0009-S5-P0_5',\n",
       "  'training_0009-S5-P1_5',\n",
       "  'training_0009-S5-P2_5',\n",
       "  'training_0009-S5-P3_5',\n",
       "  'training_0009-S5-P4_5',\n",
       "  'training_0009-S6-P0_5',\n",
       "  'training_0009-S6-P1_5',\n",
       "  'training_0009-S6-P2_5',\n",
       "  'training_0009-S6-P3_5',\n",
       "  'training_0009-S6-P4_5',\n",
       "  'training_0009-S7-P0_5',\n",
       "  'training_0009-S7-P1_5',\n",
       "  'training_0009-S7-P2_5',\n",
       "  'training_0009-S7-P3_5',\n",
       "  'training_0009-S7-P4_5',\n",
       "  'training_0009-S8-P0_5',\n",
       "  'training_0009-S8-P1_5',\n",
       "  'training_0009-S8-P2_5',\n",
       "  'training_0009-S8-P3_5',\n",
       "  'training_0009-S8-P4_5',\n",
       "  'training_0009-S9-P0_5',\n",
       "  'training_0009-S9-P1_5',\n",
       "  'training_0009-S9-P2_5',\n",
       "  'training_0009-S9-P3_5',\n",
       "  'training_0009-S9-P4_5'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = set(config_df[\"run\"])\n",
    "y = set(scenario_feats_df[\"scenario_name\"])\n",
    "x.difference(y), y.difference(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D-model</th>\n",
       "      <th>D-conf</th>\n",
       "      <th>D-seq-pol</th>\n",
       "      <th>T-model</th>\n",
       "      <th>T-min-iou</th>\n",
       "      <th>T-max-age</th>\n",
       "      <th>T-every-nth-det</th>\n",
       "      <th>score</th>\n",
       "      <th>avg_bbox_longevity</th>\n",
       "      <th>90p_bbox_longevity</th>\n",
       "      <th>90p_num_bboxes</th>\n",
       "      <th>90p_bbox_speed</th>\n",
       "      <th>90p_bbox_size</th>\n",
       "      <th>avg_num_bboxes</th>\n",
       "      <th>avg_bbox_speed</th>\n",
       "      <th>avg_bbox_size</th>\n",
       "      <th>avg_ego_speed</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>efficientdet-d1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>tail-aware</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>82.293223</td>\n",
       "      <td>26078.894492</td>\n",
       "      <td>5.517220</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>efficientdet-d1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.937269</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>82.293223</td>\n",
       "      <td>26078.894492</td>\n",
       "      <td>5.517220</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>efficientdet-d1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tail-aware</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.306273</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>82.293223</td>\n",
       "      <td>26078.894492</td>\n",
       "      <td>5.517220</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>efficientdet-d2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>wait</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>26.199262</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>82.293223</td>\n",
       "      <td>26078.894492</td>\n",
       "      <td>5.517220</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>efficientdet-d2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eager</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>82.293223</td>\n",
       "      <td>26078.894492</td>\n",
       "      <td>5.517220</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_sf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S9-P4_5</th>\n",
       "      <td>efficientdet-d7x</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tail-aware</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.938156</td>\n",
       "      <td>30.607143</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.083428</td>\n",
       "      <td>2655.662579</td>\n",
       "      <td>22.552632</td>\n",
       "      <td>8.904308</td>\n",
       "      <td>1774.223721</td>\n",
       "      <td>2.669348</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S9-P4_5</th>\n",
       "      <td>efficientdet-d7x</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tail-aware</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>28.821470</td>\n",
       "      <td>30.607143</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.083428</td>\n",
       "      <td>2655.662579</td>\n",
       "      <td>22.552632</td>\n",
       "      <td>8.904308</td>\n",
       "      <td>1774.223721</td>\n",
       "      <td>2.669348</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S9-P4_5</th>\n",
       "      <td>efficientdet-d7x</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tail-aware</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>29.638273</td>\n",
       "      <td>30.607143</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.083428</td>\n",
       "      <td>2655.662579</td>\n",
       "      <td>22.552632</td>\n",
       "      <td>8.904308</td>\n",
       "      <td>1774.223721</td>\n",
       "      <td>2.669348</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S9-P4_5</th>\n",
       "      <td>efficientdet-d7x</td>\n",
       "      <td>0.5</td>\n",
       "      <td>wait</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.404901</td>\n",
       "      <td>30.607143</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.083428</td>\n",
       "      <td>2655.662579</td>\n",
       "      <td>22.552632</td>\n",
       "      <td>8.904308</td>\n",
       "      <td>1774.223721</td>\n",
       "      <td>2.669348</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S9-P4_5</th>\n",
       "      <td>efficientdet-d7x</td>\n",
       "      <td>0.5</td>\n",
       "      <td>wait</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.404901</td>\n",
       "      <td>30.607143</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.083428</td>\n",
       "      <td>2655.662579</td>\n",
       "      <td>22.552632</td>\n",
       "      <td>8.904308</td>\n",
       "      <td>1774.223721</td>\n",
       "      <td>2.669348</td>\n",
       "      <td>Day</td>\n",
       "      <td>location_phx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36450 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                D-model  D-conf   D-seq-pol T-model  \\\n",
       "training_0000-S0-P0_5   efficientdet-d1     0.3  tail-aware    sort   \n",
       "training_0000-S0-P0_5   efficientdet-d1     0.5       eager    sort   \n",
       "training_0000-S0-P0_5   efficientdet-d1     0.5  tail-aware    sort   \n",
       "training_0000-S0-P0_5   efficientdet-d2     0.3        wait    sort   \n",
       "training_0000-S0-P0_5   efficientdet-d2     0.5       eager    sort   \n",
       "...                                 ...     ...         ...     ...   \n",
       "training_0005-S9-P4_5  efficientdet-d7x     0.5  tail-aware    sort   \n",
       "training_0005-S9-P4_5  efficientdet-d7x     0.5  tail-aware    sort   \n",
       "training_0005-S9-P4_5  efficientdet-d7x     0.5  tail-aware    sort   \n",
       "training_0005-S9-P4_5  efficientdet-d7x     0.5        wait    sort   \n",
       "training_0005-S9-P4_5  efficientdet-d7x     0.5        wait    sort   \n",
       "\n",
       "                       T-min-iou  T-max-age  T-every-nth-det      score  \\\n",
       "training_0000-S0-P0_5        0.1          1                3  25.555556   \n",
       "training_0000-S0-P0_5        0.1          3                1  26.937269   \n",
       "training_0000-S0-P0_5        0.1          1                1  27.306273   \n",
       "training_0000-S0-P0_5        0.1          7                1  26.199262   \n",
       "training_0000-S0-P0_5        0.1          7                3  23.333333   \n",
       "...                          ...        ...              ...        ...   \n",
       "training_0005-S9-P4_5        0.1          1                1  28.938156   \n",
       "training_0005-S9-P4_5        0.1          7                3  28.821470   \n",
       "training_0005-S9-P4_5        0.1          7                5  29.638273   \n",
       "training_0005-S9-P4_5        0.1          3                1  29.404901   \n",
       "training_0005-S9-P4_5        0.2          3                1  29.404901   \n",
       "\n",
       "                       avg_bbox_longevity  90p_bbox_longevity  90p_num_bboxes  \\\n",
       "training_0000-S0-P0_5           18.800000                36.0            10.1   \n",
       "training_0000-S0-P0_5           18.800000                36.0            10.1   \n",
       "training_0000-S0-P0_5           18.800000                36.0            10.1   \n",
       "training_0000-S0-P0_5           18.800000                36.0            10.1   \n",
       "training_0000-S0-P0_5           18.800000                36.0            10.1   \n",
       "...                                   ...                 ...             ...   \n",
       "training_0005-S9-P4_5           30.607143                38.0            24.0   \n",
       "training_0005-S9-P4_5           30.607143                38.0            24.0   \n",
       "training_0005-S9-P4_5           30.607143                38.0            24.0   \n",
       "training_0005-S9-P4_5           30.607143                38.0            24.0   \n",
       "training_0005-S9-P4_5           30.607143                38.0            24.0   \n",
       "\n",
       "                       90p_bbox_speed  90p_bbox_size  avg_num_bboxes  \\\n",
       "training_0000-S0-P0_5      135.227854   36462.177860        7.050000   \n",
       "training_0000-S0-P0_5      135.227854   36462.177860        7.050000   \n",
       "training_0000-S0-P0_5      135.227854   36462.177860        7.050000   \n",
       "training_0000-S0-P0_5      135.227854   36462.177860        7.050000   \n",
       "training_0000-S0-P0_5      135.227854   36462.177860        7.050000   \n",
       "...                               ...            ...             ...   \n",
       "training_0005-S9-P4_5       13.083428    2655.662579       22.552632   \n",
       "training_0005-S9-P4_5       13.083428    2655.662579       22.552632   \n",
       "training_0005-S9-P4_5       13.083428    2655.662579       22.552632   \n",
       "training_0005-S9-P4_5       13.083428    2655.662579       22.552632   \n",
       "training_0005-S9-P4_5       13.083428    2655.662579       22.552632   \n",
       "\n",
       "                       avg_bbox_speed  avg_bbox_size  avg_ego_speed  \\\n",
       "training_0000-S0-P0_5       82.293223   26078.894492       5.517220   \n",
       "training_0000-S0-P0_5       82.293223   26078.894492       5.517220   \n",
       "training_0000-S0-P0_5       82.293223   26078.894492       5.517220   \n",
       "training_0000-S0-P0_5       82.293223   26078.894492       5.517220   \n",
       "training_0000-S0-P0_5       82.293223   26078.894492       5.517220   \n",
       "...                               ...            ...            ...   \n",
       "training_0005-S9-P4_5        8.904308    1774.223721       2.669348   \n",
       "training_0005-S9-P4_5        8.904308    1774.223721       2.669348   \n",
       "training_0005-S9-P4_5        8.904308    1774.223721       2.669348   \n",
       "training_0005-S9-P4_5        8.904308    1774.223721       2.669348   \n",
       "training_0005-S9-P4_5        8.904308    1774.223721       2.669348   \n",
       "\n",
       "                      time_of_day      location  \n",
       "training_0000-S0-P0_5         Day   location_sf  \n",
       "training_0000-S0-P0_5         Day   location_sf  \n",
       "training_0000-S0-P0_5         Day   location_sf  \n",
       "training_0000-S0-P0_5         Day   location_sf  \n",
       "training_0000-S0-P0_5         Day   location_sf  \n",
       "...                           ...           ...  \n",
       "training_0005-S9-P4_5         Day  location_phx  \n",
       "training_0005-S9-P4_5         Day  location_phx  \n",
       "training_0005-S9-P4_5         Day  location_phx  \n",
       "training_0005-S9-P4_5         Day  location_phx  \n",
       "training_0005-S9-P4_5         Day  location_phx  \n",
       "\n",
       "[36450 rows x 19 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df = config_df.set_index('run').join(scenario_feats_df.set_index('scenario_name'), lsuffix=\"_config_df\", rsuffix=\"_scenario_df\", how=\"inner\")\n",
    "# assert not joined_df.isnull().values.any(), \"Some values are Nan after join, it means some scenarios in config_df don't show up in scenario_df\"\n",
    "# assert not joined_df.isna().values.any(), \"Some values are Nan after join, it means some scenarios in config_df don't show up in scenario_df\"\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D-conf</th>\n",
       "      <th>T-min-iou</th>\n",
       "      <th>T-max-age</th>\n",
       "      <th>T-every-nth-det</th>\n",
       "      <th>score</th>\n",
       "      <th>avg_bbox_longevity</th>\n",
       "      <th>90p_bbox_longevity</th>\n",
       "      <th>90p_num_bboxes</th>\n",
       "      <th>90p_bbox_speed</th>\n",
       "      <th>90p_bbox_size</th>\n",
       "      <th>...</th>\n",
       "      <th>D-seq-pol__tail-aware</th>\n",
       "      <th>D-seq-pol__wait</th>\n",
       "      <th>T-model__sort</th>\n",
       "      <th>time_of_day__Dawn/Dusk</th>\n",
       "      <th>time_of_day__Day</th>\n",
       "      <th>time_of_day__Night</th>\n",
       "      <th>location__location_other</th>\n",
       "      <th>location__location_phx</th>\n",
       "      <th>location__location_sf</th>\n",
       "      <th>scenario_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>training_0000-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.937269</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>training_0000-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.306273</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>training_0000-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>26.199262</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>training_0000-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>training_0000-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S9-P4_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.938156</td>\n",
       "      <td>30.607143</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.083428</td>\n",
       "      <td>2655.662579</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training_0005-S9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S9-P4_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>28.821470</td>\n",
       "      <td>30.607143</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.083428</td>\n",
       "      <td>2655.662579</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training_0005-S9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S9-P4_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>29.638273</td>\n",
       "      <td>30.607143</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.083428</td>\n",
       "      <td>2655.662579</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training_0005-S9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S9-P4_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.404901</td>\n",
       "      <td>30.607143</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.083428</td>\n",
       "      <td>2655.662579</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training_0005-S9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S9-P4_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.404901</td>\n",
       "      <td>30.607143</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.083428</td>\n",
       "      <td>2655.662579</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training_0005-S9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36450 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       D-conf  T-min-iou  T-max-age  T-every-nth-det  \\\n",
       "training_0000-S0-P0_5     0.3        0.1          1                3   \n",
       "training_0000-S0-P0_5     0.5        0.1          3                1   \n",
       "training_0000-S0-P0_5     0.5        0.1          1                1   \n",
       "training_0000-S0-P0_5     0.3        0.1          7                1   \n",
       "training_0000-S0-P0_5     0.5        0.1          7                3   \n",
       "...                       ...        ...        ...              ...   \n",
       "training_0005-S9-P4_5     0.5        0.1          1                1   \n",
       "training_0005-S9-P4_5     0.5        0.1          7                3   \n",
       "training_0005-S9-P4_5     0.5        0.1          7                5   \n",
       "training_0005-S9-P4_5     0.5        0.1          3                1   \n",
       "training_0005-S9-P4_5     0.5        0.2          3                1   \n",
       "\n",
       "                           score  avg_bbox_longevity  90p_bbox_longevity  \\\n",
       "training_0000-S0-P0_5  25.555556           18.800000                36.0   \n",
       "training_0000-S0-P0_5  26.937269           18.800000                36.0   \n",
       "training_0000-S0-P0_5  27.306273           18.800000                36.0   \n",
       "training_0000-S0-P0_5  26.199262           18.800000                36.0   \n",
       "training_0000-S0-P0_5  23.333333           18.800000                36.0   \n",
       "...                          ...                 ...                 ...   \n",
       "training_0005-S9-P4_5  28.938156           30.607143                38.0   \n",
       "training_0005-S9-P4_5  28.821470           30.607143                38.0   \n",
       "training_0005-S9-P4_5  29.638273           30.607143                38.0   \n",
       "training_0005-S9-P4_5  29.404901           30.607143                38.0   \n",
       "training_0005-S9-P4_5  29.404901           30.607143                38.0   \n",
       "\n",
       "                       90p_num_bboxes  90p_bbox_speed  90p_bbox_size  ...  \\\n",
       "training_0000-S0-P0_5            10.1      135.227854   36462.177860  ...   \n",
       "training_0000-S0-P0_5            10.1      135.227854   36462.177860  ...   \n",
       "training_0000-S0-P0_5            10.1      135.227854   36462.177860  ...   \n",
       "training_0000-S0-P0_5            10.1      135.227854   36462.177860  ...   \n",
       "training_0000-S0-P0_5            10.1      135.227854   36462.177860  ...   \n",
       "...                               ...             ...            ...  ...   \n",
       "training_0005-S9-P4_5            24.0       13.083428    2655.662579  ...   \n",
       "training_0005-S9-P4_5            24.0       13.083428    2655.662579  ...   \n",
       "training_0005-S9-P4_5            24.0       13.083428    2655.662579  ...   \n",
       "training_0005-S9-P4_5            24.0       13.083428    2655.662579  ...   \n",
       "training_0005-S9-P4_5            24.0       13.083428    2655.662579  ...   \n",
       "\n",
       "                       D-seq-pol__tail-aware  D-seq-pol__wait  T-model__sort  \\\n",
       "training_0000-S0-P0_5                      1                0              1   \n",
       "training_0000-S0-P0_5                      0                0              1   \n",
       "training_0000-S0-P0_5                      1                0              1   \n",
       "training_0000-S0-P0_5                      0                1              1   \n",
       "training_0000-S0-P0_5                      0                0              1   \n",
       "...                                      ...              ...            ...   \n",
       "training_0005-S9-P4_5                      1                0              1   \n",
       "training_0005-S9-P4_5                      1                0              1   \n",
       "training_0005-S9-P4_5                      1                0              1   \n",
       "training_0005-S9-P4_5                      0                1              1   \n",
       "training_0005-S9-P4_5                      0                1              1   \n",
       "\n",
       "                       time_of_day__Dawn/Dusk  time_of_day__Day  \\\n",
       "training_0000-S0-P0_5                       0                 1   \n",
       "training_0000-S0-P0_5                       0                 1   \n",
       "training_0000-S0-P0_5                       0                 1   \n",
       "training_0000-S0-P0_5                       0                 1   \n",
       "training_0000-S0-P0_5                       0                 1   \n",
       "...                                       ...               ...   \n",
       "training_0005-S9-P4_5                       0                 1   \n",
       "training_0005-S9-P4_5                       0                 1   \n",
       "training_0005-S9-P4_5                       0                 1   \n",
       "training_0005-S9-P4_5                       0                 1   \n",
       "training_0005-S9-P4_5                       0                 1   \n",
       "\n",
       "                       time_of_day__Night  location__location_other  \\\n",
       "training_0000-S0-P0_5                   0                         0   \n",
       "training_0000-S0-P0_5                   0                         0   \n",
       "training_0000-S0-P0_5                   0                         0   \n",
       "training_0000-S0-P0_5                   0                         0   \n",
       "training_0000-S0-P0_5                   0                         0   \n",
       "...                                   ...                       ...   \n",
       "training_0005-S9-P4_5                   0                         0   \n",
       "training_0005-S9-P4_5                   0                         0   \n",
       "training_0005-S9-P4_5                   0                         0   \n",
       "training_0005-S9-P4_5                   0                         0   \n",
       "training_0005-S9-P4_5                   0                         0   \n",
       "\n",
       "                       location__location_phx  location__location_sf  \\\n",
       "training_0000-S0-P0_5                       0                      1   \n",
       "training_0000-S0-P0_5                       0                      1   \n",
       "training_0000-S0-P0_5                       0                      1   \n",
       "training_0000-S0-P0_5                       0                      1   \n",
       "training_0000-S0-P0_5                       0                      1   \n",
       "...                                       ...                    ...   \n",
       "training_0005-S9-P4_5                       1                      0   \n",
       "training_0005-S9-P4_5                       1                      0   \n",
       "training_0005-S9-P4_5                       1                      0   \n",
       "training_0005-S9-P4_5                       1                      0   \n",
       "training_0005-S9-P4_5                       1                      0   \n",
       "\n",
       "                          scenario_name  \n",
       "training_0000-S0-P0_5  training_0000-S0  \n",
       "training_0000-S0-P0_5  training_0000-S0  \n",
       "training_0000-S0-P0_5  training_0000-S0  \n",
       "training_0000-S0-P0_5  training_0000-S0  \n",
       "training_0000-S0-P0_5  training_0000-S0  \n",
       "...                                 ...  \n",
       "training_0005-S9-P4_5  training_0005-S9  \n",
       "training_0005-S9-P4_5  training_0005-S9  \n",
       "training_0005-S9-P4_5  training_0005-S9  \n",
       "training_0005-S9-P4_5  training_0005-S9  \n",
       "training_0005-S9-P4_5  training_0005-S9  \n",
       "\n",
       "[36450 rows x 33 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df = pd.get_dummies(joined_df, prefix_sep=\"__\")\n",
    "joined_df[\"scenario_name\"] = joined_df.index.map(lambda x: \"-\".join(x.split(\"-\")[:2]))\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the labels\n",
    "labels = np.array(joined_df.pop('score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario examples are fairly balanced, so we just do train-test and cross-v splits across scenario boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='scenario_name', ylabel='Count'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = joined_df[\"scenario_name\"].value_counts()\n",
    "sns.histplot(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual train-test split across scenario boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "unique_scenarios = list(joined_df[\"scenario_name\"].unique())\n",
    "unique_scenarios = sorted(unique_scenarios)\n",
    "random.shuffle(unique_scenarios, random=lambda: 0.43)\n",
    "train_scenarios = unique_scenarios[len(unique_scenarios)//3:]\n",
    "test_scenarios = unique_scenarios[:len(unique_scenarios)//3]\n",
    "\n",
    "train, train_labels = joined_df[joined_df[\"scenario_name\"].isin(train_scenarios)], labels[joined_df[\"scenario_name\"].isin(train_scenarios)]\n",
    "test, test_labels = joined_df[joined_df[\"scenario_name\"].isin(test_scenarios)], labels[joined_df[\"scenario_name\"].isin(test_scenarios)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training_0004-S3',\n",
       " 'training_0000-S7',\n",
       " 'training_0004-S7',\n",
       " 'training_0000-S8',\n",
       " 'training_0005-S10',\n",
       " 'training_0000-S9',\n",
       " 'training_0005-S15',\n",
       " 'training_0005-S17',\n",
       " 'training_0001-S0',\n",
       " 'training_0005-S21',\n",
       " 'training_0001-S1',\n",
       " 'training_0005-S3',\n",
       " 'training_0001-S10',\n",
       " 'training_0005-S8',\n",
       " 'training_0002-S23',\n",
       " 'training_0001-S11',\n",
       " 'training_0002-S3',\n",
       " 'training_0001-S12',\n",
       " 'training_0002-S5',\n",
       " 'training_0001-S13',\n",
       " 'training_0002-S7',\n",
       " 'training_0002-S8',\n",
       " 'training_0001-S14',\n",
       " 'training_0003-S0',\n",
       " 'training_0001-S15',\n",
       " 'training_0003-S10',\n",
       " 'training_0001-S16',\n",
       " 'training_0003-S12',\n",
       " 'training_0003-S13',\n",
       " 'training_0001-S17',\n",
       " 'training_0003-S15',\n",
       " 'training_0001-S18',\n",
       " 'training_0003-S17',\n",
       " 'training_0001-S19',\n",
       " 'training_0003-S19',\n",
       " 'training_0003-S2',\n",
       " 'training_0001-S2',\n",
       " 'training_0003-S21',\n",
       " 'training_0001-S20',\n",
       " 'training_0003-S23',\n",
       " 'training_0001-S21',\n",
       " 'training_0003-S3',\n",
       " 'training_0003-S4',\n",
       " 'training_0001-S22',\n",
       " 'training_0003-S6',\n",
       " 'training_0001-S23',\n",
       " 'training_0003-S8',\n",
       " 'training_0001-S3',\n",
       " 'training_0004-S0',\n",
       " 'training_0001-S4',\n",
       " 'training_0004-S10',\n",
       " 'training_0004-S11',\n",
       " 'training_0001-S5',\n",
       " 'training_0004-S13',\n",
       " 'training_0001-S6',\n",
       " 'training_0004-S15',\n",
       " 'training_0001-S7',\n",
       " 'training_0004-S17',\n",
       " 'training_0004-S18',\n",
       " 'training_0001-S8',\n",
       " 'training_0004-S2',\n",
       " 'training_0001-S9',\n",
       " 'training_0004-S21',\n",
       " 'training_0002-S0',\n",
       " 'training_0004-S23',\n",
       " 'training_0004-S24',\n",
       " 'training_0002-S1',\n",
       " 'training_0004-S4',\n",
       " 'training_0002-S10',\n",
       " 'training_0004-S6',\n",
       " 'training_0002-S11',\n",
       " 'training_0004-S8',\n",
       " 'training_0004-S9',\n",
       " 'training_0002-S12',\n",
       " 'training_0005-S1',\n",
       " 'training_0002-S13',\n",
       " 'training_0005-S11',\n",
       " 'training_0002-S14',\n",
       " 'training_0005-S13',\n",
       " 'training_0005-S14',\n",
       " 'training_0002-S15',\n",
       " 'training_0005-S16',\n",
       " 'training_0002-S16',\n",
       " 'training_0005-S18',\n",
       " 'training_0002-S17',\n",
       " 'training_0005-S2',\n",
       " 'training_0005-S20',\n",
       " 'training_0002-S18',\n",
       " 'training_0005-S22',\n",
       " 'training_0002-S19',\n",
       " 'training_0005-S24',\n",
       " 'training_0002-S2',\n",
       " 'training_0005-S4',\n",
       " 'training_0005-S5',\n",
       " 'training_0002-S20',\n",
       " 'training_0005-S7',\n",
       " 'training_0002-S21',\n",
       " 'training_0005-S9',\n",
       " 'training_0002-S22']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=[\"scenario_name\"])\n",
    "test = test.drop(columns=[\"scenario_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated cross-validation splitter across scenario boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['D-conf',\n",
       "  'T-min-iou',\n",
       "  'T-max-age',\n",
       "  'T-every-nth-det',\n",
       "  'avg_bbox_longevity',\n",
       "  '90p_bbox_longevity',\n",
       "  '90p_num_bboxes',\n",
       "  '90p_bbox_speed',\n",
       "  '90p_bbox_size',\n",
       "  'avg_num_bboxes',\n",
       "  'avg_bbox_speed',\n",
       "  'avg_bbox_size',\n",
       "  'avg_ego_speed',\n",
       "  'D-model__efficientdet-d1',\n",
       "  'D-model__efficientdet-d2',\n",
       "  'D-model__efficientdet-d3',\n",
       "  'D-model__efficientdet-d4',\n",
       "  'D-model__efficientdet-d5',\n",
       "  'D-model__efficientdet-d6',\n",
       "  'D-model__efficientdet-d7',\n",
       "  'D-model__efficientdet-d7x',\n",
       "  'D-seq-pol__eager',\n",
       "  'D-seq-pol__tail-aware',\n",
       "  'D-seq-pol__wait',\n",
       "  'T-model__sort',\n",
       "  'time_of_day__Dawn/Dusk',\n",
       "  'time_of_day__Day',\n",
       "  'time_of_day__Night',\n",
       "  'location__location_other',\n",
       "  'location__location_phx',\n",
       "  'location__location_sf'],\n",
       " 31)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features for feature importances\n",
    "features = list(train.columns)\n",
    "features, len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a bit of a cross-val hyperparameter search. This is very rudimentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "model = RandomForestRegressor(n_estimators=1600, \n",
    "                               random_state=RSEED, \n",
    "                               max_features = 'sqrt',\n",
    "                               n_jobs=-1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.0015, 0.002, 0.005, 0.01]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.00005,0.0001,0.0002,0.0005,0.001,0.0015,0.002,0.005,0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = loguniform(0.00005, 0.05, scale=2).rvs(size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6646., 1027.,  564.,  402.,  334.,  292.,  224.,  181.,  182.,\n",
       "         148.]),\n",
       " array([0.00010013, 0.01008544, 0.02007074, 0.03005605, 0.04004135,\n",
       "        0.05002666, 0.06001197, 0.06999727, 0.07998258, 0.08996789,\n",
       "        0.09995319]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = randint(3,10).rvs(size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0, 1442, 1435, 1412, 1412, 1462, 1428, 1409])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.bincount(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5:48am start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ad_config_search.rforest_utils import ScenarioAwareCVSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    4.7s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 164 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 514 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 164 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 514 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 518 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 512 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 962 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 518 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 968 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 172 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 522 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 166 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 516 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 518 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 968 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1518 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 163 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 513 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 963 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1513 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 512 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 962 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1512 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 518 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 173 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 523 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 168 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 518 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 170 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 520 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 166 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 516 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 167 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 517 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 164 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 514 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 167 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 517 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 165 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 515 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 738 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 165 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 515 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 965 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 164 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 514 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 964 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 167 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 517 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 967 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 163 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 513 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 963 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1513 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 512 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 962 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1512 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 518 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 164 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 514 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 164 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 514 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 964 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1514 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done  35 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 385 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 835 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1385 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=144)]: Done 2113 out of 2400 | elapsed:    1.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 740 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 164 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 514 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 964 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done   8 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done  60 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 410 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 860 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1313 out of 1600 | elapsed:    0.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 167 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 517 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 967 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 512 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 962 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1600 out of 1600 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 167 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 517 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 172 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 522 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 166 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 516 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1644 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 400 out of 400 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 167 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 517 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 967 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1517 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.6s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 200 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 114 out of 200 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=144)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 167 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 517 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done  23 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 373 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 513 out of 800 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 526 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 976 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=144)]: Done 1526 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 962 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=144)]: Done 1512 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=144)]: Done 2400 out of 2400 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    5.7s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 167 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 517 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 967 tasks      | elapsed:    0.6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomizedSearchCV(model, {\n",
    "    \"max_depth\": randint(1, 25),\n",
    "    \"max_features\": randint(2, 24),\n",
    "    \"n_estimators\": [200, 400, 800, 1600, 2400],\n",
    "    \"min_impurity_decrease\": loguniform(0.00005, 0.05, scale=2)\n",
    "}, cv=ScenarioAwareCVSplitter(n_splits=5, shuffle=True, random_state=RSEED), n_iter=100)\n",
    "clf.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.74958267, 2.80145597, 6.48357983, 1.03626213, 1.0140976 ,\n",
       "        2.93601074, 3.09417405, 1.09135976, 1.98263555, 3.21953845,\n",
       "        7.81049051, 0.99534807, 1.76040773, 3.04820814, 2.92213635,\n",
       "        0.93095961, 1.76330562, 1.8506793 , 2.90171404, 4.85480762,\n",
       "        8.18014584, 1.77029133, 3.00533352, 3.15749879, 7.62656693,\n",
       "        5.16043873, 0.95713701, 0.93632402, 1.94476247, 5.34869962,\n",
       "        2.86676278, 0.93118634, 0.94332843, 1.7914351 , 7.85578327,\n",
       "        1.00653768, 1.75431089, 8.04491119, 1.07721367, 3.06285434,\n",
       "        6.87661219, 3.06579723, 0.98112288, 0.93078151, 1.77044234,\n",
       "        8.30052404, 1.98601246, 2.01387711, 1.02430215, 1.7181581 ,\n",
       "        2.98492227, 1.80847893, 5.78170347, 5.11879539, 3.04414849,\n",
       "        3.15028377, 6.87693911, 2.95684986, 1.81409659, 1.04382992,\n",
       "        5.18020372, 3.20451298, 6.53652282, 8.94815855, 0.97364941,\n",
       "        7.54580345, 0.96956224, 5.16365991, 2.99596057, 7.30022717,\n",
       "        3.33370476, 2.99465842, 0.91664057, 6.88358617, 5.31965647,\n",
       "        6.77172227, 4.84258881, 3.1145287 , 7.26230264, 3.6974906 ,\n",
       "        1.73571634, 6.66503515, 0.98183084, 0.93349485, 0.95585189,\n",
       "        0.91851535, 7.24214554, 7.39394283, 0.94524531, 8.42017508,\n",
       "        6.5578752 , 1.7772222 , 7.6629478 , 0.97075515, 5.25182643,\n",
       "        5.17479119, 5.52002444, 0.94197197, 1.77521262, 6.57314939]),\n",
       " 'std_fit_time': array([1.72994645, 0.08984168, 0.98701364, 0.01485631, 0.01664197,\n",
       "        0.08748085, 0.05744069, 0.0353076 , 0.03379625, 0.06801357,\n",
       "        1.47969686, 0.05130302, 0.02195696, 0.10337826, 0.08833863,\n",
       "        0.02410919, 0.07139421, 0.03434252, 0.09122123, 0.07246129,\n",
       "        1.53952588, 0.02951053, 0.11679438, 0.09343666, 0.03587352,\n",
       "        0.13461225, 0.00763716, 0.02272937, 0.0587606 , 0.81380825,\n",
       "        0.06268796, 0.00692787, 0.01929504, 0.06288374, 0.09313285,\n",
       "        0.03696461, 0.08054804, 0.2303825 , 0.05662476, 0.06863409,\n",
       "        0.1662623 , 0.19614873, 0.01913581, 0.01958501, 0.07829937,\n",
       "        0.06551428, 0.05697118, 0.04951071, 0.00665552, 0.06689376,\n",
       "        0.08381524, 0.06250658, 0.0629102 , 0.77671669, 0.14245602,\n",
       "        0.18002011, 0.23905897, 0.14486892, 0.08848473, 0.01944102,\n",
       "        0.03668052, 0.061742  , 0.06749437, 1.66943265, 0.01772156,\n",
       "        0.14444141, 0.01784487, 0.08062473, 0.0727375 , 0.11074462,\n",
       "        0.27447588, 0.08257537, 0.02595052, 0.05351457, 0.04887626,\n",
       "        0.11912835, 0.07569224, 0.09170003, 0.15596845, 0.26683846,\n",
       "        0.05314478, 0.08612414, 0.02035232, 0.02055272, 0.02174637,\n",
       "        0.02544307, 0.13466312, 0.07876781, 0.04476781, 0.28614979,\n",
       "        0.8672547 , 0.03034299, 1.18090552, 0.06878565, 0.09305915,\n",
       "        0.09798722, 0.72696615, 0.09257499, 0.06538979, 0.12923558]),\n",
       " 'mean_score_time': array([0.29031324, 0.62064834, 1.15677462, 0.26255445, 0.21977062,\n",
       "        0.59066162, 0.58226199, 0.26823912, 0.36551981, 0.60249052,\n",
       "        1.49683442, 0.23670316, 0.37984233, 0.57906513, 0.58343873,\n",
       "        0.2155828 , 0.3489212 , 0.37787232, 0.61942835, 1.08575125,\n",
       "        1.6246397 , 0.360812  , 0.55839033, 0.55850997, 1.53864093,\n",
       "        1.01427841, 0.28947816, 0.26734633, 0.36850743, 0.99106522,\n",
       "        0.57689953, 0.28043742, 0.27970891, 0.36542959, 1.6271194 ,\n",
       "        0.26584468, 0.34083982, 1.59706116, 0.21869812, 0.61431203,\n",
       "        1.48197913, 0.59529076, 0.29469619, 0.28224363, 0.36168513,\n",
       "        1.54624472, 0.36507053, 0.37015715, 0.2709301 , 0.32231431,\n",
       "        0.5620976 , 0.34015369, 1.08907866, 1.02966552, 0.57843347,\n",
       "        0.63604479, 1.55345054, 0.55870957, 0.32199392, 0.26438942,\n",
       "        1.01616106, 0.63946152, 1.57970757, 1.63218131, 0.28071241,\n",
       "        1.63721457, 0.25557623, 1.0963264 , 0.56722112, 1.52208676,\n",
       "        0.58340387, 0.57513146, 0.24852958, 1.57957973, 1.04822836,\n",
       "        1.46178241, 1.1272203 , 0.66391158, 1.57344465, 0.59477401,\n",
       "        0.34600425, 1.42140536, 0.28147945, 0.25604458, 0.23598294,\n",
       "        0.27873001, 1.66304145, 1.55271454, 0.26536288, 1.67562141,\n",
       "        1.13183169, 0.3691071 , 1.50829635, 0.23480105, 1.02394791,\n",
       "        1.04431739, 1.06417184, 0.25321879, 0.35562363, 1.57559018]),\n",
       " 'std_score_time': array([0.06150567, 0.0507108 , 0.07984101, 0.01558184, 0.0442208 ,\n",
       "        0.0412446 , 0.04085778, 0.02482295, 0.0193025 , 0.0512913 ,\n",
       "        0.13008622, 0.03796413, 0.04981227, 0.0491051 , 0.0556024 ,\n",
       "        0.04302097, 0.04762611, 0.03891029, 0.05150096, 0.0184243 ,\n",
       "        0.06455219, 0.05734461, 0.00137461, 0.00438023, 0.07883769,\n",
       "        0.0592335 , 0.06924245, 0.02327225, 0.02110153, 0.04270323,\n",
       "        0.06401603, 0.0461334 , 0.04698747, 0.07549677, 0.07574207,\n",
       "        0.02358381, 0.07910564, 0.06936925, 0.04375582, 0.06445374,\n",
       "        0.12184784, 0.07578428, 0.07641089, 0.05585427, 0.01301624,\n",
       "        0.06662727, 0.015412  , 0.02649647, 0.03048204, 0.0505661 ,\n",
       "        0.00178208, 0.03868129, 0.04841586, 0.07445703, 0.04233775,\n",
       "        0.1066535 , 0.05337194, 0.0053117 , 0.04877031, 0.01800465,\n",
       "        0.06602321, 0.04419059, 0.06071407, 0.07047048, 0.04786815,\n",
       "        0.05976812, 0.00181427, 0.03781436, 0.01922698, 0.05802634,\n",
       "        0.04640052, 0.03244389, 0.049177  , 0.06486787, 0.07329617,\n",
       "        0.09198502, 0.07548008, 0.0586125 , 0.0973915 , 0.06856859,\n",
       "        0.07399366, 0.0660067 , 0.05578104, 0.07307414, 0.03387439,\n",
       "        0.04848354, 0.04299817, 0.06810116, 0.02216096, 0.0969197 ,\n",
       "        0.08417888, 0.07428993, 0.09030941, 0.03661147, 0.07422997,\n",
       "        0.07753328, 0.00523227, 0.00257193, 0.00167173, 0.10144787]),\n",
       " 'param_max_depth': masked_array(data=[3, 9, 22, 17, 14, 7, 9, 17, 17, 17, 7, 12, 16, 9, 1, 1,\n",
       "                    11, 11, 7, 10, 19, 13, 8, 14, 17, 10, 8, 2, 17, 3, 1,\n",
       "                    11, 16, 12, 18, 12, 1, 16, 19, 13, 8, 8, 16, 5, 20, 23,\n",
       "                    18, 22, 13, 7, 11, 12, 21, 2, 8, 13, 19, 15, 14, 24,\n",
       "                    11, 18, 21, 15, 10, 13, 5, 20, 8, 24, 19, 6, 10, 11,\n",
       "                    14, 2, 2, 14, 16, 20, 5, 3, 14, 4, 14, 11, 23, 14, 6,\n",
       "                    23, 24, 12, 3, 23, 15, 14, 13, 7, 7, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[14, 3, 21, 17, 6, 11, 23, 16, 16, 9, 12, 16, 7, 16, 18,\n",
       "                    15, 8, 23, 11, 2, 23, 8, 16, 18, 16, 5, 19, 3, 21, 11,\n",
       "                    21, 4, 2, 19, 7, 22, 8, 22, 23, 4, 8, 6, 9, 15, 9, 8,\n",
       "                    16, 11, 23, 7, 4, 12, 22, 11, 15, 14, 2, 3, 6, 5, 21,\n",
       "                    16, 2, 13, 21, 18, 9, 16, 12, 15, 8, 21, 11, 2, 13, 17,\n",
       "                    23, 2, 7, 15, 12, 2, 13, 18, 8, 2, 11, 14, 6, 13, 9, 7,\n",
       "                    21, 10, 13, 6, 9, 19, 21, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_impurity_decrease': masked_array(data=[0.0014316509842798337, 0.004950978333616284,\n",
       "                    0.0003974330792593261, 0.002394565003679478,\n",
       "                    0.00043804261010248235, 0.06215699772489517,\n",
       "                    0.0009046674766924689, 0.00013845041818429617,\n",
       "                    0.0002675348934385855, 0.002533118890668921,\n",
       "                    0.05951706822971039, 0.015495475221942213,\n",
       "                    0.006738937525743244, 0.06469762123697907,\n",
       "                    0.00013933144138511663, 0.007615988330383594,\n",
       "                    0.00939231164181836, 0.0019448115400841925,\n",
       "                    0.05662237803410734, 0.0006630624494769555,\n",
       "                    0.023380765161198483, 0.006675922373995921,\n",
       "                    0.025254563527423318, 0.04648373972830889,\n",
       "                    0.005271917062285709, 0.0015651476965345614,\n",
       "                    0.0001239699799321393, 0.008954649481249306,\n",
       "                    0.005921018794540314, 0.0003035615998461246,\n",
       "                    0.005273367408283691, 0.00011768294730098595,\n",
       "                    0.007205532561019888, 0.010004069852362506,\n",
       "                    0.0014164206374765356, 0.0008062738038173675,\n",
       "                    0.0008303478887319863, 0.0003672110018333348,\n",
       "                    0.001239005078873772, 0.0009074117901790606,\n",
       "                    0.0001308851261658519, 0.0008228272354351349,\n",
       "                    0.007775221118055102, 0.004727943245589756,\n",
       "                    0.02368252497346027, 0.0006237328048522971,\n",
       "                    0.0008972684401325904, 0.0003020731518365501,\n",
       "                    0.00022629759259488875, 0.0856275095794566,\n",
       "                    0.0003826540255192558, 0.0013209696321281985,\n",
       "                    0.0010697279259854796, 0.03929215606679123,\n",
       "                    0.0009262559761987263, 0.038773239298978676,\n",
       "                    0.020839280062287958, 0.010230033695864959,\n",
       "                    0.0005445868195543045, 0.00028751800950435125,\n",
       "                    0.006950220808017438, 0.006146641093948204,\n",
       "                    0.03916068149012895, 0.002788162674835879,\n",
       "                    0.0503237496493194, 0.0019516961504239387,\n",
       "                    0.03604518989100999, 0.09972557134286314,\n",
       "                    0.00013698049250118185, 0.034719057236059746,\n",
       "                    0.0019072153315017456, 0.001570987135011636,\n",
       "                    0.09896816107819172, 0.00012362338777607924,\n",
       "                    0.007531105270491644, 0.03652256219671874,\n",
       "                    0.0006205638936771123, 0.00013129602661239418,\n",
       "                    0.024397594505731954, 0.0003335231180884177,\n",
       "                    0.00017658327001553303, 0.03250439545964591,\n",
       "                    0.0010964474221393206, 0.054711565291250576,\n",
       "                    0.004165537324908982, 0.008899489230167238,\n",
       "                    0.02710585416556446, 0.004790624125365473,\n",
       "                    0.0032438646872880728, 0.0004114940272683308,\n",
       "                    0.00023078517807537612, 0.0019563672455086716,\n",
       "                    0.0004711874924608265, 0.017924627098623004,\n",
       "                    0.003344880782934856, 0.0025555698088445124,\n",
       "                    0.0021437987391040316, 0.000204770468756481,\n",
       "                    0.0007905116222084572, 0.0007014734813300656],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[200, 800, 1600, 200, 200, 800, 800, 200, 400, 800,\n",
       "                    2400, 200, 400, 800, 800, 200, 400, 400, 800, 1600,\n",
       "                    2400, 400, 800, 800, 2400, 1600, 200, 200, 400, 1600,\n",
       "                    800, 200, 200, 400, 2400, 200, 400, 2400, 200, 800,\n",
       "                    2400, 800, 200, 200, 400, 2400, 400, 400, 200, 400,\n",
       "                    800, 400, 1600, 1600, 800, 800, 2400, 800, 400, 200,\n",
       "                    1600, 800, 2400, 2400, 200, 2400, 200, 1600, 800, 2400,\n",
       "                    800, 800, 200, 2400, 1600, 2400, 1600, 800, 2400, 800,\n",
       "                    400, 2400, 200, 200, 200, 200, 2400, 2400, 200, 2400,\n",
       "                    1600, 400, 2400, 200, 1600, 1600, 1600, 200, 400, 2400],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 3,\n",
       "   'max_features': 14,\n",
       "   'min_impurity_decrease': 0.0014316509842798337,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_impurity_decrease': 0.004950978333616284,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 22,\n",
       "   'max_features': 21,\n",
       "   'min_impurity_decrease': 0.0003974330792593261,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 17,\n",
       "   'max_features': 17,\n",
       "   'min_impurity_decrease': 0.002394565003679478,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 14,\n",
       "   'max_features': 6,\n",
       "   'min_impurity_decrease': 0.00043804261010248235,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 11,\n",
       "   'min_impurity_decrease': 0.06215699772489517,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 9,\n",
       "   'max_features': 23,\n",
       "   'min_impurity_decrease': 0.0009046674766924689,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 17,\n",
       "   'max_features': 16,\n",
       "   'min_impurity_decrease': 0.00013845041818429617,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 17,\n",
       "   'max_features': 16,\n",
       "   'min_impurity_decrease': 0.0002675348934385855,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 17,\n",
       "   'max_features': 9,\n",
       "   'min_impurity_decrease': 0.002533118890668921,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 12,\n",
       "   'min_impurity_decrease': 0.05951706822971039,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 16,\n",
       "   'min_impurity_decrease': 0.015495475221942213,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 16,\n",
       "   'max_features': 7,\n",
       "   'min_impurity_decrease': 0.006738937525743244,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 9,\n",
       "   'max_features': 16,\n",
       "   'min_impurity_decrease': 0.06469762123697907,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 1,\n",
       "   'max_features': 18,\n",
       "   'min_impurity_decrease': 0.00013933144138511663,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 1,\n",
       "   'max_features': 15,\n",
       "   'min_impurity_decrease': 0.007615988330383594,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 11,\n",
       "   'max_features': 8,\n",
       "   'min_impurity_decrease': 0.00939231164181836,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 11,\n",
       "   'max_features': 23,\n",
       "   'min_impurity_decrease': 0.0019448115400841925,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 11,\n",
       "   'min_impurity_decrease': 0.05662237803410734,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 2,\n",
       "   'min_impurity_decrease': 0.0006630624494769555,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 19,\n",
       "   'max_features': 23,\n",
       "   'min_impurity_decrease': 0.023380765161198483,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 13,\n",
       "   'max_features': 8,\n",
       "   'min_impurity_decrease': 0.006675922373995921,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 16,\n",
       "   'min_impurity_decrease': 0.025254563527423318,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 14,\n",
       "   'max_features': 18,\n",
       "   'min_impurity_decrease': 0.04648373972830889,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 17,\n",
       "   'max_features': 16,\n",
       "   'min_impurity_decrease': 0.005271917062285709,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_impurity_decrease': 0.0015651476965345614,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 19,\n",
       "   'min_impurity_decrease': 0.0001239699799321393,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_impurity_decrease': 0.008954649481249306,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 17,\n",
       "   'max_features': 21,\n",
       "   'min_impurity_decrease': 0.005921018794540314,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 3,\n",
       "   'max_features': 11,\n",
       "   'min_impurity_decrease': 0.0003035615998461246,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 1,\n",
       "   'max_features': 21,\n",
       "   'min_impurity_decrease': 0.005273367408283691,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 11,\n",
       "   'max_features': 4,\n",
       "   'min_impurity_decrease': 0.00011768294730098595,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 16,\n",
       "   'max_features': 2,\n",
       "   'min_impurity_decrease': 0.007205532561019888,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 19,\n",
       "   'min_impurity_decrease': 0.010004069852362506,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 18,\n",
       "   'max_features': 7,\n",
       "   'min_impurity_decrease': 0.0014164206374765356,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 22,\n",
       "   'min_impurity_decrease': 0.0008062738038173675,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 1,\n",
       "   'max_features': 8,\n",
       "   'min_impurity_decrease': 0.0008303478887319863,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 16,\n",
       "   'max_features': 22,\n",
       "   'min_impurity_decrease': 0.0003672110018333348,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 19,\n",
       "   'max_features': 23,\n",
       "   'min_impurity_decrease': 0.001239005078873772,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 13,\n",
       "   'max_features': 4,\n",
       "   'min_impurity_decrease': 0.0009074117901790606,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 8,\n",
       "   'min_impurity_decrease': 0.0001308851261658519,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 6,\n",
       "   'min_impurity_decrease': 0.0008228272354351349,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 16,\n",
       "   'max_features': 9,\n",
       "   'min_impurity_decrease': 0.007775221118055102,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 15,\n",
       "   'min_impurity_decrease': 0.004727943245589756,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 20,\n",
       "   'max_features': 9,\n",
       "   'min_impurity_decrease': 0.02368252497346027,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 23,\n",
       "   'max_features': 8,\n",
       "   'min_impurity_decrease': 0.0006237328048522971,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 18,\n",
       "   'max_features': 16,\n",
       "   'min_impurity_decrease': 0.0008972684401325904,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 22,\n",
       "   'max_features': 11,\n",
       "   'min_impurity_decrease': 0.0003020731518365501,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 13,\n",
       "   'max_features': 23,\n",
       "   'min_impurity_decrease': 0.00022629759259488875,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_impurity_decrease': 0.0856275095794566,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 11,\n",
       "   'max_features': 4,\n",
       "   'min_impurity_decrease': 0.0003826540255192558,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 12,\n",
       "   'min_impurity_decrease': 0.0013209696321281985,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 21,\n",
       "   'max_features': 22,\n",
       "   'min_impurity_decrease': 0.0010697279259854796,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 11,\n",
       "   'min_impurity_decrease': 0.03929215606679123,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 15,\n",
       "   'min_impurity_decrease': 0.0009262559761987263,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 13,\n",
       "   'max_features': 14,\n",
       "   'min_impurity_decrease': 0.038773239298978676,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 19,\n",
       "   'max_features': 2,\n",
       "   'min_impurity_decrease': 0.020839280062287958,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 15,\n",
       "   'max_features': 3,\n",
       "   'min_impurity_decrease': 0.010230033695864959,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 14,\n",
       "   'max_features': 6,\n",
       "   'min_impurity_decrease': 0.0005445868195543045,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 24,\n",
       "   'max_features': 5,\n",
       "   'min_impurity_decrease': 0.00028751800950435125,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 11,\n",
       "   'max_features': 21,\n",
       "   'min_impurity_decrease': 0.006950220808017438,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 18,\n",
       "   'max_features': 16,\n",
       "   'min_impurity_decrease': 0.006146641093948204,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 21,\n",
       "   'max_features': 2,\n",
       "   'min_impurity_decrease': 0.03916068149012895,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 15,\n",
       "   'max_features': 13,\n",
       "   'min_impurity_decrease': 0.002788162674835879,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 21,\n",
       "   'min_impurity_decrease': 0.0503237496493194,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 13,\n",
       "   'max_features': 18,\n",
       "   'min_impurity_decrease': 0.0019516961504239387,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_impurity_decrease': 0.03604518989100999,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 20,\n",
       "   'max_features': 16,\n",
       "   'min_impurity_decrease': 0.09972557134286314,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 12,\n",
       "   'min_impurity_decrease': 0.00013698049250118185,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 24,\n",
       "   'max_features': 15,\n",
       "   'min_impurity_decrease': 0.034719057236059746,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 19,\n",
       "   'max_features': 8,\n",
       "   'min_impurity_decrease': 0.0019072153315017456,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 21,\n",
       "   'min_impurity_decrease': 0.001570987135011636,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 11,\n",
       "   'min_impurity_decrease': 0.09896816107819172,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 11,\n",
       "   'max_features': 2,\n",
       "   'min_impurity_decrease': 0.00012362338777607924,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 14,\n",
       "   'max_features': 13,\n",
       "   'min_impurity_decrease': 0.007531105270491644,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 17,\n",
       "   'min_impurity_decrease': 0.03652256219671874,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 23,\n",
       "   'min_impurity_decrease': 0.0006205638936771123,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 14,\n",
       "   'max_features': 2,\n",
       "   'min_impurity_decrease': 0.00013129602661239418,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 16,\n",
       "   'max_features': 7,\n",
       "   'min_impurity_decrease': 0.024397594505731954,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 20,\n",
       "   'max_features': 15,\n",
       "   'min_impurity_decrease': 0.0003335231180884177,\n",
       "   'n_estimators': 800},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 12,\n",
       "   'min_impurity_decrease': 0.00017658327001553303,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_impurity_decrease': 0.03250439545964591,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 14,\n",
       "   'max_features': 13,\n",
       "   'min_impurity_decrease': 0.0010964474221393206,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 18,\n",
       "   'min_impurity_decrease': 0.054711565291250576,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 14,\n",
       "   'max_features': 8,\n",
       "   'min_impurity_decrease': 0.004165537324908982,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 11,\n",
       "   'max_features': 2,\n",
       "   'min_impurity_decrease': 0.008899489230167238,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 23,\n",
       "   'max_features': 11,\n",
       "   'min_impurity_decrease': 0.02710585416556446,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 14,\n",
       "   'max_features': 14,\n",
       "   'min_impurity_decrease': 0.004790624125365473,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_impurity_decrease': 0.0032438646872880728,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 23,\n",
       "   'max_features': 13,\n",
       "   'min_impurity_decrease': 0.0004114940272683308,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 24,\n",
       "   'max_features': 9,\n",
       "   'min_impurity_decrease': 0.00023078517807537612,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 7,\n",
       "   'min_impurity_decrease': 0.0019563672455086716,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 3,\n",
       "   'max_features': 21,\n",
       "   'min_impurity_decrease': 0.0004711874924608265,\n",
       "   'n_estimators': 2400},\n",
       "  {'max_depth': 23,\n",
       "   'max_features': 10,\n",
       "   'min_impurity_decrease': 0.017924627098623004,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 15,\n",
       "   'max_features': 13,\n",
       "   'min_impurity_decrease': 0.003344880782934856,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 14,\n",
       "   'max_features': 6,\n",
       "   'min_impurity_decrease': 0.0025555698088445124,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 13,\n",
       "   'max_features': 9,\n",
       "   'min_impurity_decrease': 0.0021437987391040316,\n",
       "   'n_estimators': 1600},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 19,\n",
       "   'min_impurity_decrease': 0.000204770468756481,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 21,\n",
       "   'min_impurity_decrease': 0.0007905116222084572,\n",
       "   'n_estimators': 400},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 4,\n",
       "   'min_impurity_decrease': 0.0007014734813300656,\n",
       "   'n_estimators': 2400}],\n",
       " 'split0_test_score': array([0.056332  , 0.07512868, 0.17254751, 0.1616884 , 0.10564982,\n",
       "        0.09736308, 0.16803547, 0.15330975, 0.1548461 , 0.12081987,\n",
       "        0.1047188 , 0.14924929, 0.12316063, 0.14111617, 0.00496622,\n",
       "        0.0079566 , 0.1221812 , 0.17924421, 0.09755256, 0.08045866,\n",
       "        0.17329888, 0.1092722 , 0.14010302, 0.15702579, 0.15729167,\n",
       "        0.09344464, 0.16466727, 0.03325806, 0.17637946, 0.05261466,\n",
       "        0.00381685, 0.0938966 , 0.09675375, 0.17387816, 0.11561051,\n",
       "        0.20012955, 0.0152673 , 0.17376786, 0.17511091, 0.10687151,\n",
       "        0.09413664, 0.08991324, 0.12529641, 0.09621052, 0.1208179 ,\n",
       "        0.12079761, 0.1616938 , 0.15080516, 0.17742047, 0.07566204,\n",
       "        0.09443918, 0.12287487, 0.17391275, 0.04140925, 0.13114154,\n",
       "        0.1485426 , 0.08703093, 0.09261346, 0.09997266, 0.1042536 ,\n",
       "        0.16308531, 0.16037281, 0.07850591, 0.14415871, 0.18081588,\n",
       "        0.1633546 , 0.0649922 , 0.14699265, 0.11668375, 0.15453544,\n",
       "        0.11725236, 0.13822921, 0.12272646, 0.09183244, 0.1373237 ,\n",
       "        0.03049582, 0.02022084, 0.09686923, 0.11267225, 0.15140921,\n",
       "        0.06174147, 0.04276844, 0.14417999, 0.0526239 , 0.13507748,\n",
       "        0.07688156, 0.12539406, 0.14638596, 0.06160162, 0.14057048,\n",
       "        0.12027033, 0.12098065, 0.02870874, 0.14790629, 0.13285817,\n",
       "        0.106467  , 0.11842202, 0.1322682 , 0.15026492, 0.05860579]),\n",
       " 'split1_test_score': array([0.29756995, 0.44505117, 0.58987744, 0.58066433, 0.5526471 ,\n",
       "        0.48338744, 0.52990752, 0.59125473, 0.60205629, 0.59322921,\n",
       "        0.48552692, 0.55928778, 0.57210361, 0.52794814, 0.10676127,\n",
       "        0.12128694, 0.55458382, 0.54959469, 0.48290266, 0.41727458,\n",
       "        0.56920813, 0.56955255, 0.51654259, 0.57692889, 0.59357403,\n",
       "        0.49836838, 0.50956661, 0.18007288, 0.58016332, 0.30308402,\n",
       "        0.09973217, 0.50701675, 0.44140401, 0.56996954, 0.58415423,\n",
       "        0.56374664, 0.13579953, 0.58262033, 0.58329186, 0.5219367 ,\n",
       "        0.4972336 , 0.4778728 , 0.58222438, 0.42176428, 0.57094182,\n",
       "        0.59734857, 0.60915519, 0.5995212 , 0.5739309 , 0.46291348,\n",
       "        0.49775519, 0.58313634, 0.57786529, 0.22665784, 0.5118505 ,\n",
       "        0.56864352, 0.43196895, 0.49726666, 0.56419483, 0.57148606,\n",
       "        0.56033244, 0.59539033, 0.40249265, 0.58866494, 0.53710972,\n",
       "        0.57567291, 0.41538626, 0.56629222, 0.51198247, 0.57821167,\n",
       "        0.59664127, 0.45258817, 0.54172275, 0.4400383 , 0.5841656 ,\n",
       "        0.21847587, 0.19427922, 0.47298724, 0.56102962, 0.60510658,\n",
       "        0.41656718, 0.19667011, 0.58847417, 0.36233476, 0.56783773,\n",
       "        0.40978783, 0.58476135, 0.58410905, 0.41685247, 0.60237159,\n",
       "        0.5976009 , 0.55753803, 0.2710356 , 0.58148738, 0.58884129,\n",
       "        0.56447909, 0.57124906, 0.48633194, 0.48477497, 0.31329303]),\n",
       " 'split2_test_score': array([0.26399001, 0.46608425, 0.53701985, 0.55533157, 0.56019542,\n",
       "        0.45228435, 0.46720216, 0.55536881, 0.54676026, 0.54863469,\n",
       "        0.44808604, 0.49572049, 0.57005351, 0.49198765, 0.05319544,\n",
       "        0.06806768, 0.53060153, 0.50081923, 0.44751929, 0.45500093,\n",
       "        0.52068115, 0.53802558, 0.46999875, 0.53126597, 0.54787387,\n",
       "        0.51301547, 0.46067727, 0.16552821, 0.53648374, 0.26260971,\n",
       "        0.03986187, 0.52093748, 0.51298583, 0.51985018, 0.57579084,\n",
       "        0.50964607, 0.1068202 , 0.52313126, 0.51634853, 0.55046563,\n",
       "        0.47107555, 0.47635064, 0.55424762, 0.37881231, 0.53273981,\n",
       "        0.5702322 , 0.5376237 , 0.5822753 , 0.51448152, 0.44539714,\n",
       "        0.52904789, 0.52768048, 0.52790105, 0.18596154, 0.46182113,\n",
       "        0.54380491, 0.48635883, 0.54078024, 0.5607687 , 0.57450994,\n",
       "        0.50769777, 0.54575375, 0.44922411, 0.54616451, 0.48870183,\n",
       "        0.5282696 , 0.3799974 , 0.52577435, 0.46905344, 0.54558473,\n",
       "        0.57116736, 0.40938173, 0.50539253, 0.48977176, 0.54641275,\n",
       "        0.18011219, 0.16930779, 0.53959988, 0.55420226, 0.5526287 ,\n",
       "        0.38046006, 0.19117873, 0.5240627 , 0.31988849, 0.56305192,\n",
       "        0.45820499, 0.55418479, 0.54500586, 0.40443929, 0.55832061,\n",
       "        0.57213378, 0.52429563, 0.27063541, 0.55915932, 0.54480796,\n",
       "        0.56074263, 0.55079658, 0.44223552, 0.43530242, 0.29705513]),\n",
       " 'split3_test_score': array([-1.28634743, -0.23374359, -1.93864853, -1.48111361, -0.37987372,\n",
       "        -0.88907623, -2.19439808, -1.19701301, -1.18555178, -0.6687322 ,\n",
       "        -0.93444345, -1.20206156, -0.44381802, -1.32390003, -1.08971811,\n",
       "        -0.87440911, -0.58532715, -1.94761947, -0.90299936, -0.13068861,\n",
       "        -2.13114738, -0.57570779, -1.35061961, -1.62028253, -1.3014071 ,\n",
       "        -0.31587345, -1.4574983 , -0.08501659, -1.83551131, -0.88919478,\n",
       "        -1.30387774, -0.26823666, -0.20597688, -1.46954982, -0.44457   ,\n",
       "        -2.02976365, -0.31861465, -2.01909211, -1.9155721 , -0.24740527,\n",
       "        -0.57856781, -0.49399043, -0.65075944, -1.40791254, -0.60309844,\n",
       "        -0.53415331, -1.19477417, -0.7904109 , -1.92082312, -0.45262622,\n",
       "        -0.26057161, -0.84151399, -1.98080521, -0.89986438, -1.30265476,\n",
       "        -1.21302887, -0.07255964, -0.20857292, -0.41391578, -0.30701468,\n",
       "        -1.9533535 , -1.30918569, -0.07814397, -1.00299128, -1.93402192,\n",
       "        -1.55210466, -0.61104268, -1.28085099, -1.02580501, -1.20860905,\n",
       "        -0.56523489, -1.9920348 , -0.84263053, -0.11906427, -1.02708786,\n",
       "        -1.48328362, -2.09952959, -0.11682567, -0.44807728, -1.30122173,\n",
       "        -0.81437773, -0.06336976, -0.99374187, -1.41464666, -0.53512574,\n",
       "        -0.2666721 , -0.80771703, -1.1457803 , -0.49358661, -0.99712355,\n",
       "        -0.63541823, -0.43665167, -1.83697618, -0.71471678, -1.02381634,\n",
       "        -0.39823899, -0.67061636, -1.4383462 , -1.88963728, -0.29034746]),\n",
       " 'split4_test_score': array([0.23074434, 0.45451472, 0.26158627, 0.31672023, 0.48347265,\n",
       "        0.28562926, 0.15264161, 0.25476006, 0.26654217, 0.41287841,\n",
       "        0.29181153, 0.25191709, 0.49393327, 0.19444618, 0.040254  ,\n",
       "        0.05731013, 0.42114355, 0.19200419, 0.28400898, 0.44775024,\n",
       "        0.24257907, 0.44077837, 0.20342721, 0.19644798, 0.26203708,\n",
       "        0.47380479, 0.17528668, 0.165923  , 0.2162697 , 0.24573403,\n",
       "        0.02853973, 0.48133542, 0.49027522, 0.225319  , 0.49052284,\n",
       "        0.22904941, 0.10247517, 0.23456224, 0.24909545, 0.50846146,\n",
       "        0.39191103, 0.42377367, 0.44030073, 0.27041506, 0.41362143,\n",
       "        0.46855996, 0.28161657, 0.37949171, 0.21323602, 0.40335449,\n",
       "        0.48703785, 0.35025221, 0.2439667 , 0.16202317, 0.21121441,\n",
       "        0.24629281, 0.46280599, 0.5100646 , 0.47926801, 0.51690399,\n",
       "        0.23955404, 0.22701459, 0.43312886, 0.32177718, 0.17588058,\n",
       "        0.23113721, 0.36172172, 0.25048287, 0.29587487, 0.29176472,\n",
       "        0.45743739, 0.20114454, 0.34590941, 0.47504087, 0.30064384,\n",
       "        0.13732887, 0.15200274, 0.50949979, 0.48195165, 0.24663828,\n",
       "        0.30691198, 0.18886582, 0.37867458, 0.28074896, 0.43728478,\n",
       "        0.43863629, 0.38204561, 0.28768353, 0.38010246, 0.33410913,\n",
       "        0.42476278, 0.46774431, 0.28162759, 0.39885635, 0.30594941,\n",
       "        0.50315039, 0.40142007, 0.16580198, 0.16887134, 0.29853035]),\n",
       " 'mean_test_score': array([-0.08754223,  0.24140705, -0.07552349,  0.02665818,  0.26441826,\n",
       "         0.08591758, -0.17532226,  0.07153607,  0.07693061,  0.201366  ,\n",
       "         0.07913997,  0.05082262,  0.2630866 ,  0.00631962, -0.17690824,\n",
       "        -0.12395755,  0.20863659, -0.10519143,  0.08179683,  0.25395916,\n",
       "        -0.12507603,  0.21638418, -0.00410961, -0.03172278,  0.05187391,\n",
       "         0.25255197, -0.02946009,  0.09195311, -0.06524302, -0.00503047,\n",
       "        -0.22638543,  0.26698992,  0.26708838,  0.00389341,  0.26430168,\n",
       "        -0.10543839,  0.00834951, -0.10100208, -0.07834507,  0.288066  ,\n",
       "         0.1751578 ,  0.19478398,  0.21026194, -0.04814207,  0.2070045 ,\n",
       "         0.24455701,  0.07906302,  0.18433649, -0.08835084,  0.18694018,\n",
       "         0.2695417 ,  0.14848598, -0.09143188, -0.05676252,  0.00267457,\n",
       "         0.05885099,  0.27912101,  0.28643041,  0.25805769,  0.29202778,\n",
       "        -0.09653679,  0.04386916,  0.25704151,  0.11955481, -0.11030278,\n",
       "        -0.01073407,  0.12221098,  0.04173822,  0.0735579 ,  0.0722975 ,\n",
       "         0.2354527 , -0.15813823,  0.13462412,  0.27552382,  0.10829161,\n",
       "        -0.18337417, -0.3127438 ,  0.30042609,  0.2523557 ,  0.05091221,\n",
       "         0.07026059,  0.11122267,  0.12832992, -0.07981011,  0.23362523,\n",
       "         0.22336772,  0.16773376,  0.08348082,  0.15388185,  0.12764965,\n",
       "         0.21586991,  0.24678139, -0.19699377,  0.19453851,  0.1097281 ,\n",
       "         0.26732002,  0.19425427, -0.04234171, -0.13008473,  0.13542737]),\n",
       " 'std_test_score': array([0.60514897, 0.27956476, 0.94492168, 0.76969647, 0.36300534,\n",
       "        0.50652455, 1.02101016, 0.65630425, 0.65305161, 0.46528451,\n",
       "        0.52431029, 0.64440927, 0.39046224, 0.68279071, 0.45757529,\n",
       "        0.37694971, 0.42575887, 0.9337841 , 0.51099909, 0.23778184,\n",
       "        1.01464801, 0.42834951, 0.6888854 , 0.81223435, 0.6965782 ,\n",
       "        0.32423521, 0.72796761, 0.10335697, 0.90001168, 0.45044825,\n",
       "        0.5396684 , 0.31127962, 0.28052397, 0.75307538, 0.39372967,\n",
       "        0.97307955, 0.16837639, 0.97201371, 0.931481  , 0.31358704,\n",
       "        0.40322421, 0.37343364, 0.46003848, 0.68911451, 0.43472735,\n",
       "        0.42483166, 0.65753974, 0.5138241 , 0.92968464, 0.34963536,\n",
       "        0.30932522, 0.52041808, 0.95751382, 0.42604406, 0.66842396,\n",
       "        0.65664696, 0.22831034, 0.29723772, 0.37704831, 0.34715225,\n",
       "        0.94071309, 0.69770144, 0.21601907, 0.5837241 , 0.92418093,\n",
       "        0.78727758, 0.38748055, 0.68019746, 0.56718891, 0.65963634,\n",
       "        0.43531843, 0.92467941, 0.51049157, 0.24585221, 0.59081892,\n",
       "        0.65298716, 0.89542217, 0.26314547, 0.38709768, 0.69792913,\n",
       "        0.45930673, 0.10477709, 0.58143029, 0.67595581, 0.41530395,\n",
       "        0.28207757, 0.5142923 , 0.63566858, 0.34952522, 0.58630122,\n",
       "        0.45828146, 0.37558355, 0.8255048 , 0.48027977, 0.5903905 ,\n",
       "        0.37386061, 0.46171785, 0.7123134 , 0.89013605, 0.23304423]),\n",
       " 'rank_test_score': array([ 83,  21,  80,  66,  11,  50,  95,  58,  55,  30,  53,  63,  13,\n",
       "         68,  96,  91,  28,  88,  52,  16,  92,  25,  71,  75,  61,  17,\n",
       "         74,  49,  79,  72,  99,  10,   9,  69,  12,  89,  67,  87,  81,\n",
       "          3,  36,  31,  27,  77,  29,  20,  54,  35,  84,  34,   7,  39,\n",
       "         85,  78,  70,  60,   5,   4,  14,   2,  86,  64,  15,  45,  90,\n",
       "         73,  44,  65,  56,  57,  22,  94,  41,   6,  48,  97, 100,   1,\n",
       "         18,  62,  59,  46,  42,  82,  23,  24,  37,  51,  38,  43,  26,\n",
       "         19,  98,  32,  47,   8,  33,  76,  93,  40], dtype=int32)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-scenario grained\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=14, max_features=2,\n",
       "                      min_impurity_decrease=0.00013129602661239418,\n",
       "                      n_estimators=800, n_jobs=-1, random_state=50, verbose=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-scenario grained\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 512 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=14, max_features=2,\n",
       "                      min_impurity_decrease=0.00013129602661239418,\n",
       "                      n_estimators=800, n_jobs=-1, random_state=50, verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model with 100 trees\n",
    "model = RandomForestRegressor(\n",
    "max_depth=14, max_features=2,\n",
    "                      min_impurity_decrease=0.00013129602661239418,\n",
    "                      n_estimators=800,\n",
    "    random_state=RSEED, \n",
    "#                               max_features = 'sqrt',\n",
    "                              n_jobs=-1, verbose = 1)\n",
    "# Fit on training data\n",
    "model.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('avg_num_bboxes', 0.10005660698272548),\n",
       " ('avg_bbox_longevity', 0.0981805704804458),\n",
       " ('avg_ego_speed', 0.09792782609598864),\n",
       " ('avg_bbox_size', 0.09641512204274992),\n",
       " ('90p_bbox_size', 0.08966144757911479),\n",
       " ('90p_bbox_longevity', 0.08181883206891201),\n",
       " ('90p_num_bboxes', 0.07811209352396374),\n",
       " ('avg_bbox_speed', 0.07465083547814554),\n",
       " ('90p_bbox_speed', 0.07152492688472879),\n",
       " ('location__location_other', 0.027903061433726235),\n",
       " ('location__location_sf', 0.02111936234630595),\n",
       " ('T-max-age', 0.020365064687616594),\n",
       " ('T-every-nth-det', 0.0180272704938484),\n",
       " ('location__location_phx', 0.016536253374756945),\n",
       " ('D-model__efficientdet-d7x', 0.01568195000276777),\n",
       " ('D-model__efficientdet-d2', 0.012051796999324627),\n",
       " ('D-model__efficientdet-d7', 0.0101082903349845),\n",
       " ('D-model__efficientdet-d4', 0.009833824303075075),\n",
       " ('D-model__efficientdet-d1', 0.008344391852083962),\n",
       " ('D-conf', 0.007086185540822819),\n",
       " ('D-model__efficientdet-d6', 0.005926446283261899),\n",
       " ('time_of_day__Day', 0.005846078851389432),\n",
       " ('T-min-iou', 0.0052708427484022225),\n",
       " ('D-seq-pol__tail-aware', 0.005119586539418561),\n",
       " ('D-seq-pol__wait', 0.004196108429296781),\n",
       " ('D-seq-pol__eager', 0.004140034599903741),\n",
       " ('D-model__efficientdet-d5', 0.0038200621585228276),\n",
       " ('time_of_day__Dawn/Dusk', 0.0034849043860268533),\n",
       " ('D-model__efficientdet-d3', 0.0034034633559696446),\n",
       " ('time_of_day__Night', 0.003386760141720503),\n",
       " ('T-model__sort', 0.0)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(features, model.feature_importances_), key=(lambda f: f[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes 4431\n",
      "Average maximum depth 14\n"
     ]
    }
   ],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "# Stats about the trees in random forest\n",
    "for ind_tree in model.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 183 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=144)]: Done 533 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9201566272191566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=144)]: Done 164 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 514 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 183 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score 0.4479632440370763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=144)]: Done 533 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Training predictions (to demonstrate overfitting)\n",
    "train_rf_predictions = model.predict(train)\n",
    "train_score = model.score(train, train_labels)\n",
    "print(\"train score\", train_score)\n",
    "\n",
    "# Testing predictions (to determine performance)\n",
    "rf_predictions = model.predict(test)\n",
    "test_score = model.score(test, test_labels)\n",
    "print(\"test score\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"RF\"\n",
    "env_window = \"40\"\n",
    "time = \"present\"\n",
    "env_feats = \"gt-v3-fine-4s\"\n",
    "dictionary = {\n",
    "    \"model\": model,\n",
    "    \"train\": train,\n",
    "    \"train_labels\": train_labels,\n",
    "    \"test\": test,\n",
    "    \"test_labels\": test_labels,\n",
    "    \"metadata\": \"condensed config space\"\n",
    "}\n",
    "with open(\"model={}__env-window={}__time={}__env-feats={}__te={:.2f}.pl\".format(model_type, env_window, time, env_feats, test_score), 'wb') as f:\n",
    "    pickle.dump(dictionary, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using trained model to get best config and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy = train.copy()\n",
    "train_copy[\"ground_truth\"] = train_labels\n",
    "test_copy = test.copy()\n",
    "test_copy[\"ground_truth\"] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 162 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 512 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=144)]: Using backend ThreadingBackend with 144 concurrent workers.\n",
      "[Parallel(n_jobs=144)]: Done 173 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=144)]: Done 523 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=144)]: Done 800 out of 800 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "train_copy[\"prediction\"] = model.predict(train)\n",
    "test_copy[\"prediction\"] = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['training_0000-S7-P0_5', 'training_0000-S7-P1_5',\n",
       "       'training_0000-S7-P2_5', 'training_0000-S7-P3_5',\n",
       "       'training_0000-S7-P4_5', 'training_0000-S8-P0_5',\n",
       "       'training_0000-S8-P1_5', 'training_0000-S8-P2_5',\n",
       "       'training_0000-S8-P3_5', 'training_0000-S8-P4_5',\n",
       "       ...\n",
       "       'training_0005-S8-P0_5', 'training_0005-S8-P1_5',\n",
       "       'training_0005-S8-P2_5', 'training_0005-S8-P3_5',\n",
       "       'training_0005-S8-P4_5', 'training_0005-S9-P0_5',\n",
       "       'training_0005-S9-P1_5', 'training_0005-S9-P2_5',\n",
       "       'training_0005-S9-P3_5', 'training_0005-S9-P4_5'],\n",
       "      dtype='object', length=485)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['training_0000-S0-P0_5', 'training_0000-S0-P1_5',\n",
       "       'training_0000-S0-P2_5', 'training_0000-S0-P3_5',\n",
       "       'training_0000-S0-P4_5', 'training_0000-S1-P0_5',\n",
       "       'training_0000-S1-P1_5', 'training_0000-S1-P2_5',\n",
       "       'training_0000-S1-P3_5', 'training_0000-S1-P4_5',\n",
       "       ...\n",
       "       'training_0005-S19-P4_5', 'training_0005-S23-P1_5',\n",
       "       'training_0005-S23-P2_5', 'training_0005-S23-P3_5',\n",
       "       'training_0005-S23-P4_5', 'training_0005-S6-P0_5',\n",
       "       'training_0005-S6-P1_5', 'training_0005-S6-P2_5',\n",
       "       'training_0005-S6-P3_5', 'training_0005-S6-P4_5'],\n",
       "      dtype='object', length=244)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy[\"run_name\"] = train_copy.index\n",
    "test_copy[\"run_name\"] = test_copy.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predicted_configs = pd.DataFrame([rows.iloc[rows[\"prediction\"].argmax()] for run_name, rows in to_predict.groupby([\"run_name\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D-conf</th>\n",
       "      <th>T-min-iou</th>\n",
       "      <th>T-max-age</th>\n",
       "      <th>T-every-nth-det</th>\n",
       "      <th>avg_bbox_longevity</th>\n",
       "      <th>90p_bbox_longevity</th>\n",
       "      <th>90p_num_bboxes</th>\n",
       "      <th>90p_bbox_speed</th>\n",
       "      <th>90p_bbox_size</th>\n",
       "      <th>avg_num_bboxes</th>\n",
       "      <th>...</th>\n",
       "      <th>T-model__sort</th>\n",
       "      <th>time_of_day__Dawn/Dusk</th>\n",
       "      <th>time_of_day__Day</th>\n",
       "      <th>time_of_day__Night</th>\n",
       "      <th>location__location_other</th>\n",
       "      <th>location__location_phx</th>\n",
       "      <th>location__location_sf</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prediction</th>\n",
       "      <th>run_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.199262</td>\n",
       "      <td>47.313494</td>\n",
       "      <td>training_0000-S0-P0_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P1_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>90.531630</td>\n",
       "      <td>34145.917102</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.814815</td>\n",
       "      <td>56.425281</td>\n",
       "      <td>training_0000-S0-P1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P2_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30.647059</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>97.894224</td>\n",
       "      <td>29315.504548</td>\n",
       "      <td>13.025000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45.489443</td>\n",
       "      <td>54.293911</td>\n",
       "      <td>training_0000-S0-P2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P3_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.357143</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>62.063127</td>\n",
       "      <td>34060.382231</td>\n",
       "      <td>10.275000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.316302</td>\n",
       "      <td>51.585971</td>\n",
       "      <td>training_0000-S0-P3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P4_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>31.083333</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>61.554437</td>\n",
       "      <td>36439.619563</td>\n",
       "      <td>9.815789</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82.573727</td>\n",
       "      <td>54.513768</td>\n",
       "      <td>training_0000-S0-P4_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P0_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.933333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.553512</td>\n",
       "      <td>5264.382425</td>\n",
       "      <td>10.475000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.831202</td>\n",
       "      <td>22.133526</td>\n",
       "      <td>training_0005-S6-P0_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P1_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>26.407407</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>58.825172</td>\n",
       "      <td>5396.373582</td>\n",
       "      <td>17.825000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.147265</td>\n",
       "      <td>20.368751</td>\n",
       "      <td>training_0005-S6-P1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P2_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30.655172</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>48.082587</td>\n",
       "      <td>4285.257364</td>\n",
       "      <td>22.225000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.635546</td>\n",
       "      <td>20.737526</td>\n",
       "      <td>training_0005-S6-P2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P3_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.615385</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>75.865060</td>\n",
       "      <td>18234.114429</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.757225</td>\n",
       "      <td>29.559839</td>\n",
       "      <td>training_0005-S6-P3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P4_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.312500</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>56.019411</td>\n",
       "      <td>12392.732611</td>\n",
       "      <td>8.743590</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.768328</td>\n",
       "      <td>25.251624</td>\n",
       "      <td>training_0005-S6-P4_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       D-conf  T-min-iou  T-max-age  T-every-nth-det  \\\n",
       "training_0000-S0-P0_5     0.3        0.1          3                1   \n",
       "training_0000-S0-P1_5     0.3        0.2          5                1   \n",
       "training_0000-S0-P2_5     0.3        0.2          5                1   \n",
       "training_0000-S0-P3_5     0.3        0.1          1                1   \n",
       "training_0000-S0-P4_5     0.3        0.2          5                1   \n",
       "...                       ...        ...        ...              ...   \n",
       "training_0005-S6-P0_5     0.5        0.1          3                1   \n",
       "training_0005-S6-P1_5     0.3        0.2          5                1   \n",
       "training_0005-S6-P2_5     0.3        0.1          5                1   \n",
       "training_0005-S6-P3_5     0.3        0.1          1                1   \n",
       "training_0005-S6-P4_5     0.5        0.1          1                1   \n",
       "\n",
       "                       avg_bbox_longevity  90p_bbox_longevity  90p_num_bboxes  \\\n",
       "training_0000-S0-P0_5           18.800000                36.0            10.1   \n",
       "training_0000-S0-P1_5           36.000000                40.0            14.0   \n",
       "training_0000-S0-P2_5           30.647059                40.0            13.0   \n",
       "training_0000-S0-P3_5           29.357143                40.0            13.0   \n",
       "training_0000-S0-P4_5           31.083333                38.0            11.0   \n",
       "...                                   ...                 ...             ...   \n",
       "training_0005-S6-P0_5           27.933333                40.0            14.0   \n",
       "training_0005-S6-P1_5           26.407407                40.0            21.0   \n",
       "training_0005-S6-P2_5           30.655172                40.0            23.0   \n",
       "training_0005-S6-P3_5           26.615385                40.0            23.0   \n",
       "training_0005-S6-P4_5           21.312500                39.0            11.0   \n",
       "\n",
       "                       90p_bbox_speed  90p_bbox_size  avg_num_bboxes  ...  \\\n",
       "training_0000-S0-P0_5      135.227854   36462.177860        7.050000  ...   \n",
       "training_0000-S0-P1_5       90.531630   34145.917102       13.500000  ...   \n",
       "training_0000-S0-P2_5       97.894224   29315.504548       13.025000  ...   \n",
       "training_0000-S0-P3_5       62.063127   34060.382231       10.275000  ...   \n",
       "training_0000-S0-P4_5       61.554437   36439.619563        9.815789  ...   \n",
       "...                               ...            ...             ...  ...   \n",
       "training_0005-S6-P0_5       26.553512    5264.382425       10.475000  ...   \n",
       "training_0005-S6-P1_5       58.825172    5396.373582       17.825000  ...   \n",
       "training_0005-S6-P2_5       48.082587    4285.257364       22.225000  ...   \n",
       "training_0005-S6-P3_5       75.865060   18234.114429       17.300000  ...   \n",
       "training_0005-S6-P4_5       56.019411   12392.732611        8.743590  ...   \n",
       "\n",
       "                       T-model__sort  time_of_day__Dawn/Dusk  \\\n",
       "training_0000-S0-P0_5              1                       0   \n",
       "training_0000-S0-P1_5              1                       0   \n",
       "training_0000-S0-P2_5              1                       0   \n",
       "training_0000-S0-P3_5              1                       0   \n",
       "training_0000-S0-P4_5              1                       0   \n",
       "...                              ...                     ...   \n",
       "training_0005-S6-P0_5              1                       0   \n",
       "training_0005-S6-P1_5              1                       0   \n",
       "training_0005-S6-P2_5              1                       0   \n",
       "training_0005-S6-P3_5              1                       0   \n",
       "training_0005-S6-P4_5              1                       0   \n",
       "\n",
       "                       time_of_day__Day  time_of_day__Night  \\\n",
       "training_0000-S0-P0_5                 1                   0   \n",
       "training_0000-S0-P1_5                 1                   0   \n",
       "training_0000-S0-P2_5                 1                   0   \n",
       "training_0000-S0-P3_5                 1                   0   \n",
       "training_0000-S0-P4_5                 1                   0   \n",
       "...                                 ...                 ...   \n",
       "training_0005-S6-P0_5                 0                   1   \n",
       "training_0005-S6-P1_5                 0                   1   \n",
       "training_0005-S6-P2_5                 0                   1   \n",
       "training_0005-S6-P3_5                 0                   1   \n",
       "training_0005-S6-P4_5                 0                   1   \n",
       "\n",
       "                       location__location_other  location__location_phx  \\\n",
       "training_0000-S0-P0_5                         0                       0   \n",
       "training_0000-S0-P1_5                         0                       0   \n",
       "training_0000-S0-P2_5                         0                       0   \n",
       "training_0000-S0-P3_5                         0                       0   \n",
       "training_0000-S0-P4_5                         0                       0   \n",
       "...                                         ...                     ...   \n",
       "training_0005-S6-P0_5                         0                       1   \n",
       "training_0005-S6-P1_5                         0                       1   \n",
       "training_0005-S6-P2_5                         0                       1   \n",
       "training_0005-S6-P3_5                         0                       1   \n",
       "training_0005-S6-P4_5                         0                       1   \n",
       "\n",
       "                       location__location_sf  ground_truth  prediction  \\\n",
       "training_0000-S0-P0_5                      1     26.199262   47.313494   \n",
       "training_0000-S0-P1_5                      1     39.814815   56.425281   \n",
       "training_0000-S0-P2_5                      1     45.489443   54.293911   \n",
       "training_0000-S0-P3_5                      1     70.316302   51.585971   \n",
       "training_0000-S0-P4_5                      1     82.573727   54.513768   \n",
       "...                                      ...           ...         ...   \n",
       "training_0005-S6-P0_5                      0     25.831202   22.133526   \n",
       "training_0005-S6-P1_5                      0     15.147265   20.368751   \n",
       "training_0005-S6-P2_5                      0     15.635546   20.737526   \n",
       "training_0005-S6-P3_5                      0     28.757225   29.559839   \n",
       "training_0005-S6-P4_5                      0     18.768328   25.251624   \n",
       "\n",
       "                                    run_name  \n",
       "training_0000-S0-P0_5  training_0000-S0-P0_5  \n",
       "training_0000-S0-P1_5  training_0000-S0-P1_5  \n",
       "training_0000-S0-P2_5  training_0000-S0-P2_5  \n",
       "training_0000-S0-P3_5  training_0000-S0-P3_5  \n",
       "training_0000-S0-P4_5  training_0000-S0-P4_5  \n",
       "...                                      ...  \n",
       "training_0005-S6-P0_5  training_0005-S6-P0_5  \n",
       "training_0005-S6-P1_5  training_0005-S6-P1_5  \n",
       "training_0005-S6-P2_5  training_0005-S6-P2_5  \n",
       "training_0005-S6-P3_5  training_0005-S6-P3_5  \n",
       "training_0005-S6-P4_5  training_0005-S6-P4_5  \n",
       "\n",
       "[244 rows x 34 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_predicted_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_columns = set([c.split(\"__\")[0] for c in best_predicted_configs.columns if \"__\" in c])\n",
    "for pc in parent_columns:\n",
    "    ccs = list(filter(lambda cc: cc.startswith(pc), best_predicted_configs.columns))\n",
    "    rows = best_predicted_configs[ccs]\n",
    "    rows.columns = [cc.split(\"__\")[1] for cc in ccs]\n",
    "    best_predicted_configs[pc] = rows.idxmax(axis=1)\n",
    "    best_predicted_configs = best_predicted_configs.drop(columns=ccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D-conf</th>\n",
       "      <th>T-min-iou</th>\n",
       "      <th>T-max-age</th>\n",
       "      <th>T-every-nth-det</th>\n",
       "      <th>avg_bbox_longevity</th>\n",
       "      <th>90p_bbox_longevity</th>\n",
       "      <th>90p_num_bboxes</th>\n",
       "      <th>90p_bbox_speed</th>\n",
       "      <th>90p_bbox_size</th>\n",
       "      <th>avg_num_bboxes</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_bbox_size</th>\n",
       "      <th>avg_ego_speed</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prediction</th>\n",
       "      <th>run_name</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>D-model</th>\n",
       "      <th>location</th>\n",
       "      <th>T-model</th>\n",
       "      <th>D-seq-pol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>26078.894492</td>\n",
       "      <td>5.517220</td>\n",
       "      <td>26.199262</td>\n",
       "      <td>47.313494</td>\n",
       "      <td>training_0000-S0-P0_5</td>\n",
       "      <td>Day</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>sort</td>\n",
       "      <td>eager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P1_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>90.531630</td>\n",
       "      <td>34145.917102</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>25472.173016</td>\n",
       "      <td>4.531131</td>\n",
       "      <td>39.814815</td>\n",
       "      <td>56.425281</td>\n",
       "      <td>training_0000-S0-P1_5</td>\n",
       "      <td>Day</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P2_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30.647059</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>97.894224</td>\n",
       "      <td>29315.504548</td>\n",
       "      <td>13.025000</td>\n",
       "      <td>...</td>\n",
       "      <td>22558.133232</td>\n",
       "      <td>5.299616</td>\n",
       "      <td>45.489443</td>\n",
       "      <td>54.293911</td>\n",
       "      <td>training_0000-S0-P2_5</td>\n",
       "      <td>Day</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P3_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.357143</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>62.063127</td>\n",
       "      <td>34060.382231</td>\n",
       "      <td>10.275000</td>\n",
       "      <td>...</td>\n",
       "      <td>19031.671097</td>\n",
       "      <td>6.640001</td>\n",
       "      <td>70.316302</td>\n",
       "      <td>51.585971</td>\n",
       "      <td>training_0000-S0-P3_5</td>\n",
       "      <td>Day</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>sort</td>\n",
       "      <td>eager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P4_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>31.083333</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>61.554437</td>\n",
       "      <td>36439.619563</td>\n",
       "      <td>9.815789</td>\n",
       "      <td>...</td>\n",
       "      <td>23205.035151</td>\n",
       "      <td>5.972181</td>\n",
       "      <td>82.573727</td>\n",
       "      <td>54.513768</td>\n",
       "      <td>training_0000-S0-P4_5</td>\n",
       "      <td>Day</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P0_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.933333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.553512</td>\n",
       "      <td>5264.382425</td>\n",
       "      <td>10.475000</td>\n",
       "      <td>...</td>\n",
       "      <td>4669.148773</td>\n",
       "      <td>15.847261</td>\n",
       "      <td>25.831202</td>\n",
       "      <td>22.133526</td>\n",
       "      <td>training_0005-S6-P0_5</td>\n",
       "      <td>Night</td>\n",
       "      <td>efficientdet-d7x</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P1_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>26.407407</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>58.825172</td>\n",
       "      <td>5396.373582</td>\n",
       "      <td>17.825000</td>\n",
       "      <td>...</td>\n",
       "      <td>3585.298837</td>\n",
       "      <td>16.651571</td>\n",
       "      <td>15.147265</td>\n",
       "      <td>20.368751</td>\n",
       "      <td>training_0005-S6-P1_5</td>\n",
       "      <td>Night</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P2_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30.655172</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>48.082587</td>\n",
       "      <td>4285.257364</td>\n",
       "      <td>22.225000</td>\n",
       "      <td>...</td>\n",
       "      <td>3526.763419</td>\n",
       "      <td>17.575884</td>\n",
       "      <td>15.635546</td>\n",
       "      <td>20.737526</td>\n",
       "      <td>training_0005-S6-P2_5</td>\n",
       "      <td>Night</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>sort</td>\n",
       "      <td>tail-aware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P3_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.615385</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>75.865060</td>\n",
       "      <td>18234.114429</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>9840.567423</td>\n",
       "      <td>18.141886</td>\n",
       "      <td>28.757225</td>\n",
       "      <td>29.559839</td>\n",
       "      <td>training_0005-S6-P3_5</td>\n",
       "      <td>Night</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>sort</td>\n",
       "      <td>eager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P4_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.312500</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>56.019411</td>\n",
       "      <td>12392.732611</td>\n",
       "      <td>8.743590</td>\n",
       "      <td>...</td>\n",
       "      <td>5529.573584</td>\n",
       "      <td>18.967082</td>\n",
       "      <td>18.768328</td>\n",
       "      <td>25.251624</td>\n",
       "      <td>training_0005-S6-P4_5</td>\n",
       "      <td>Night</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       D-conf  T-min-iou  T-max-age  T-every-nth-det  \\\n",
       "training_0000-S0-P0_5     0.3        0.1          3                1   \n",
       "training_0000-S0-P1_5     0.3        0.2          5                1   \n",
       "training_0000-S0-P2_5     0.3        0.2          5                1   \n",
       "training_0000-S0-P3_5     0.3        0.1          1                1   \n",
       "training_0000-S0-P4_5     0.3        0.2          5                1   \n",
       "...                       ...        ...        ...              ...   \n",
       "training_0005-S6-P0_5     0.5        0.1          3                1   \n",
       "training_0005-S6-P1_5     0.3        0.2          5                1   \n",
       "training_0005-S6-P2_5     0.3        0.1          5                1   \n",
       "training_0005-S6-P3_5     0.3        0.1          1                1   \n",
       "training_0005-S6-P4_5     0.5        0.1          1                1   \n",
       "\n",
       "                       avg_bbox_longevity  90p_bbox_longevity  90p_num_bboxes  \\\n",
       "training_0000-S0-P0_5           18.800000                36.0            10.1   \n",
       "training_0000-S0-P1_5           36.000000                40.0            14.0   \n",
       "training_0000-S0-P2_5           30.647059                40.0            13.0   \n",
       "training_0000-S0-P3_5           29.357143                40.0            13.0   \n",
       "training_0000-S0-P4_5           31.083333                38.0            11.0   \n",
       "...                                   ...                 ...             ...   \n",
       "training_0005-S6-P0_5           27.933333                40.0            14.0   \n",
       "training_0005-S6-P1_5           26.407407                40.0            21.0   \n",
       "training_0005-S6-P2_5           30.655172                40.0            23.0   \n",
       "training_0005-S6-P3_5           26.615385                40.0            23.0   \n",
       "training_0005-S6-P4_5           21.312500                39.0            11.0   \n",
       "\n",
       "                       90p_bbox_speed  90p_bbox_size  avg_num_bboxes  ...  \\\n",
       "training_0000-S0-P0_5      135.227854   36462.177860        7.050000  ...   \n",
       "training_0000-S0-P1_5       90.531630   34145.917102       13.500000  ...   \n",
       "training_0000-S0-P2_5       97.894224   29315.504548       13.025000  ...   \n",
       "training_0000-S0-P3_5       62.063127   34060.382231       10.275000  ...   \n",
       "training_0000-S0-P4_5       61.554437   36439.619563        9.815789  ...   \n",
       "...                               ...            ...             ...  ...   \n",
       "training_0005-S6-P0_5       26.553512    5264.382425       10.475000  ...   \n",
       "training_0005-S6-P1_5       58.825172    5396.373582       17.825000  ...   \n",
       "training_0005-S6-P2_5       48.082587    4285.257364       22.225000  ...   \n",
       "training_0005-S6-P3_5       75.865060   18234.114429       17.300000  ...   \n",
       "training_0005-S6-P4_5       56.019411   12392.732611        8.743590  ...   \n",
       "\n",
       "                       avg_bbox_size  avg_ego_speed  ground_truth  prediction  \\\n",
       "training_0000-S0-P0_5   26078.894492       5.517220     26.199262   47.313494   \n",
       "training_0000-S0-P1_5   25472.173016       4.531131     39.814815   56.425281   \n",
       "training_0000-S0-P2_5   22558.133232       5.299616     45.489443   54.293911   \n",
       "training_0000-S0-P3_5   19031.671097       6.640001     70.316302   51.585971   \n",
       "training_0000-S0-P4_5   23205.035151       5.972181     82.573727   54.513768   \n",
       "...                              ...            ...           ...         ...   \n",
       "training_0005-S6-P0_5    4669.148773      15.847261     25.831202   22.133526   \n",
       "training_0005-S6-P1_5    3585.298837      16.651571     15.147265   20.368751   \n",
       "training_0005-S6-P2_5    3526.763419      17.575884     15.635546   20.737526   \n",
       "training_0005-S6-P3_5    9840.567423      18.141886     28.757225   29.559839   \n",
       "training_0005-S6-P4_5    5529.573584      18.967082     18.768328   25.251624   \n",
       "\n",
       "                                    run_name time_of_day           D-model  \\\n",
       "training_0000-S0-P0_5  training_0000-S0-P0_5         Day   efficientdet-d4   \n",
       "training_0000-S0-P1_5  training_0000-S0-P1_5         Day   efficientdet-d4   \n",
       "training_0000-S0-P2_5  training_0000-S0-P2_5         Day   efficientdet-d4   \n",
       "training_0000-S0-P3_5  training_0000-S0-P3_5         Day   efficientdet-d6   \n",
       "training_0000-S0-P4_5  training_0000-S0-P4_5         Day   efficientdet-d4   \n",
       "...                                      ...         ...               ...   \n",
       "training_0005-S6-P0_5  training_0005-S6-P0_5       Night  efficientdet-d7x   \n",
       "training_0005-S6-P1_5  training_0005-S6-P1_5       Night   efficientdet-d4   \n",
       "training_0005-S6-P2_5  training_0005-S6-P2_5       Night   efficientdet-d4   \n",
       "training_0005-S6-P3_5  training_0005-S6-P3_5       Night   efficientdet-d6   \n",
       "training_0005-S6-P4_5  training_0005-S6-P4_5       Night   efficientdet-d5   \n",
       "\n",
       "                           location T-model   D-seq-pol  \n",
       "training_0000-S0-P0_5   location_sf    sort       eager  \n",
       "training_0000-S0-P1_5   location_sf    sort        wait  \n",
       "training_0000-S0-P2_5   location_sf    sort        wait  \n",
       "training_0000-S0-P3_5   location_sf    sort       eager  \n",
       "training_0000-S0-P4_5   location_sf    sort        wait  \n",
       "...                             ...     ...         ...  \n",
       "training_0005-S6-P0_5  location_phx    sort        wait  \n",
       "training_0005-S6-P1_5  location_phx    sort        wait  \n",
       "training_0005-S6-P2_5  location_phx    sort  tail-aware  \n",
       "training_0005-S6-P3_5  location_phx    sort       eager  \n",
       "training_0005-S6-P4_5  location_phx    sort        wait  \n",
       "\n",
       "[244 rows x 21 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_predicted_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predicted_configs[\"scenario_name\"] = best_predicted_configs.index.map(lambda x: \"-\".join(x.split(\"-\")[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D-conf</th>\n",
       "      <th>T-min-iou</th>\n",
       "      <th>T-max-age</th>\n",
       "      <th>T-every-nth-det</th>\n",
       "      <th>avg_bbox_longevity</th>\n",
       "      <th>90p_bbox_longevity</th>\n",
       "      <th>90p_num_bboxes</th>\n",
       "      <th>90p_bbox_speed</th>\n",
       "      <th>90p_bbox_size</th>\n",
       "      <th>avg_num_bboxes</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_ego_speed</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prediction</th>\n",
       "      <th>run_name</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>D-model</th>\n",
       "      <th>location</th>\n",
       "      <th>T-model</th>\n",
       "      <th>D-seq-pol</th>\n",
       "      <th>scenario_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P0_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>135.227854</td>\n",
       "      <td>36462.177860</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.517220</td>\n",
       "      <td>26.199262</td>\n",
       "      <td>47.313494</td>\n",
       "      <td>training_0000-S0-P0_5</td>\n",
       "      <td>Day</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>sort</td>\n",
       "      <td>eager</td>\n",
       "      <td>training_0000-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P1_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>90.531630</td>\n",
       "      <td>34145.917102</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.531131</td>\n",
       "      <td>39.814815</td>\n",
       "      <td>56.425281</td>\n",
       "      <td>training_0000-S0-P1_5</td>\n",
       "      <td>Day</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "      <td>training_0000-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P2_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30.647059</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>97.894224</td>\n",
       "      <td>29315.504548</td>\n",
       "      <td>13.025000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.299616</td>\n",
       "      <td>45.489443</td>\n",
       "      <td>54.293911</td>\n",
       "      <td>training_0000-S0-P2_5</td>\n",
       "      <td>Day</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "      <td>training_0000-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P3_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.357143</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>62.063127</td>\n",
       "      <td>34060.382231</td>\n",
       "      <td>10.275000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.640001</td>\n",
       "      <td>70.316302</td>\n",
       "      <td>51.585971</td>\n",
       "      <td>training_0000-S0-P3_5</td>\n",
       "      <td>Day</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>sort</td>\n",
       "      <td>eager</td>\n",
       "      <td>training_0000-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0000-S0-P4_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>31.083333</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>61.554437</td>\n",
       "      <td>36439.619563</td>\n",
       "      <td>9.815789</td>\n",
       "      <td>...</td>\n",
       "      <td>5.972181</td>\n",
       "      <td>82.573727</td>\n",
       "      <td>54.513768</td>\n",
       "      <td>training_0000-S0-P4_5</td>\n",
       "      <td>Day</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_sf</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "      <td>training_0000-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P0_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.933333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.553512</td>\n",
       "      <td>5264.382425</td>\n",
       "      <td>10.475000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.847261</td>\n",
       "      <td>25.831202</td>\n",
       "      <td>22.133526</td>\n",
       "      <td>training_0005-S6-P0_5</td>\n",
       "      <td>Night</td>\n",
       "      <td>efficientdet-d7x</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "      <td>training_0005-S6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P1_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>26.407407</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>58.825172</td>\n",
       "      <td>5396.373582</td>\n",
       "      <td>17.825000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.651571</td>\n",
       "      <td>15.147265</td>\n",
       "      <td>20.368751</td>\n",
       "      <td>training_0005-S6-P1_5</td>\n",
       "      <td>Night</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "      <td>training_0005-S6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P2_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30.655172</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>48.082587</td>\n",
       "      <td>4285.257364</td>\n",
       "      <td>22.225000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.575884</td>\n",
       "      <td>15.635546</td>\n",
       "      <td>20.737526</td>\n",
       "      <td>training_0005-S6-P2_5</td>\n",
       "      <td>Night</td>\n",
       "      <td>efficientdet-d4</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>sort</td>\n",
       "      <td>tail-aware</td>\n",
       "      <td>training_0005-S6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P3_5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.615385</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>75.865060</td>\n",
       "      <td>18234.114429</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.141886</td>\n",
       "      <td>28.757225</td>\n",
       "      <td>29.559839</td>\n",
       "      <td>training_0005-S6-P3_5</td>\n",
       "      <td>Night</td>\n",
       "      <td>efficientdet-d6</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>sort</td>\n",
       "      <td>eager</td>\n",
       "      <td>training_0005-S6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_0005-S6-P4_5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.312500</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>56.019411</td>\n",
       "      <td>12392.732611</td>\n",
       "      <td>8.743590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.967082</td>\n",
       "      <td>18.768328</td>\n",
       "      <td>25.251624</td>\n",
       "      <td>training_0005-S6-P4_5</td>\n",
       "      <td>Night</td>\n",
       "      <td>efficientdet-d5</td>\n",
       "      <td>location_phx</td>\n",
       "      <td>sort</td>\n",
       "      <td>wait</td>\n",
       "      <td>training_0005-S6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       D-conf  T-min-iou  T-max-age  T-every-nth-det  \\\n",
       "training_0000-S0-P0_5     0.3        0.1          3                1   \n",
       "training_0000-S0-P1_5     0.3        0.2          5                1   \n",
       "training_0000-S0-P2_5     0.3        0.2          5                1   \n",
       "training_0000-S0-P3_5     0.3        0.1          1                1   \n",
       "training_0000-S0-P4_5     0.3        0.2          5                1   \n",
       "...                       ...        ...        ...              ...   \n",
       "training_0005-S6-P0_5     0.5        0.1          3                1   \n",
       "training_0005-S6-P1_5     0.3        0.2          5                1   \n",
       "training_0005-S6-P2_5     0.3        0.1          5                1   \n",
       "training_0005-S6-P3_5     0.3        0.1          1                1   \n",
       "training_0005-S6-P4_5     0.5        0.1          1                1   \n",
       "\n",
       "                       avg_bbox_longevity  90p_bbox_longevity  90p_num_bboxes  \\\n",
       "training_0000-S0-P0_5           18.800000                36.0            10.1   \n",
       "training_0000-S0-P1_5           36.000000                40.0            14.0   \n",
       "training_0000-S0-P2_5           30.647059                40.0            13.0   \n",
       "training_0000-S0-P3_5           29.357143                40.0            13.0   \n",
       "training_0000-S0-P4_5           31.083333                38.0            11.0   \n",
       "...                                   ...                 ...             ...   \n",
       "training_0005-S6-P0_5           27.933333                40.0            14.0   \n",
       "training_0005-S6-P1_5           26.407407                40.0            21.0   \n",
       "training_0005-S6-P2_5           30.655172                40.0            23.0   \n",
       "training_0005-S6-P3_5           26.615385                40.0            23.0   \n",
       "training_0005-S6-P4_5           21.312500                39.0            11.0   \n",
       "\n",
       "                       90p_bbox_speed  90p_bbox_size  avg_num_bboxes  ...  \\\n",
       "training_0000-S0-P0_5      135.227854   36462.177860        7.050000  ...   \n",
       "training_0000-S0-P1_5       90.531630   34145.917102       13.500000  ...   \n",
       "training_0000-S0-P2_5       97.894224   29315.504548       13.025000  ...   \n",
       "training_0000-S0-P3_5       62.063127   34060.382231       10.275000  ...   \n",
       "training_0000-S0-P4_5       61.554437   36439.619563        9.815789  ...   \n",
       "...                               ...            ...             ...  ...   \n",
       "training_0005-S6-P0_5       26.553512    5264.382425       10.475000  ...   \n",
       "training_0005-S6-P1_5       58.825172    5396.373582       17.825000  ...   \n",
       "training_0005-S6-P2_5       48.082587    4285.257364       22.225000  ...   \n",
       "training_0005-S6-P3_5       75.865060   18234.114429       17.300000  ...   \n",
       "training_0005-S6-P4_5       56.019411   12392.732611        8.743590  ...   \n",
       "\n",
       "                       avg_ego_speed  ground_truth  prediction  \\\n",
       "training_0000-S0-P0_5       5.517220     26.199262   47.313494   \n",
       "training_0000-S0-P1_5       4.531131     39.814815   56.425281   \n",
       "training_0000-S0-P2_5       5.299616     45.489443   54.293911   \n",
       "training_0000-S0-P3_5       6.640001     70.316302   51.585971   \n",
       "training_0000-S0-P4_5       5.972181     82.573727   54.513768   \n",
       "...                              ...           ...         ...   \n",
       "training_0005-S6-P0_5      15.847261     25.831202   22.133526   \n",
       "training_0005-S6-P1_5      16.651571     15.147265   20.368751   \n",
       "training_0005-S6-P2_5      17.575884     15.635546   20.737526   \n",
       "training_0005-S6-P3_5      18.141886     28.757225   29.559839   \n",
       "training_0005-S6-P4_5      18.967082     18.768328   25.251624   \n",
       "\n",
       "                                    run_name  time_of_day           D-model  \\\n",
       "training_0000-S0-P0_5  training_0000-S0-P0_5          Day   efficientdet-d4   \n",
       "training_0000-S0-P1_5  training_0000-S0-P1_5          Day   efficientdet-d4   \n",
       "training_0000-S0-P2_5  training_0000-S0-P2_5          Day   efficientdet-d4   \n",
       "training_0000-S0-P3_5  training_0000-S0-P3_5          Day   efficientdet-d6   \n",
       "training_0000-S0-P4_5  training_0000-S0-P4_5          Day   efficientdet-d4   \n",
       "...                                      ...          ...               ...   \n",
       "training_0005-S6-P0_5  training_0005-S6-P0_5        Night  efficientdet-d7x   \n",
       "training_0005-S6-P1_5  training_0005-S6-P1_5        Night   efficientdet-d4   \n",
       "training_0005-S6-P2_5  training_0005-S6-P2_5        Night   efficientdet-d4   \n",
       "training_0005-S6-P3_5  training_0005-S6-P3_5        Night   efficientdet-d6   \n",
       "training_0005-S6-P4_5  training_0005-S6-P4_5        Night   efficientdet-d5   \n",
       "\n",
       "                           location T-model   D-seq-pol     scenario_name  \n",
       "training_0000-S0-P0_5   location_sf    sort       eager  training_0000-S0  \n",
       "training_0000-S0-P1_5   location_sf    sort        wait  training_0000-S0  \n",
       "training_0000-S0-P2_5   location_sf    sort        wait  training_0000-S0  \n",
       "training_0000-S0-P3_5   location_sf    sort       eager  training_0000-S0  \n",
       "training_0000-S0-P4_5   location_sf    sort        wait  training_0000-S0  \n",
       "...                             ...     ...         ...               ...  \n",
       "training_0005-S6-P0_5  location_phx    sort        wait  training_0005-S6  \n",
       "training_0005-S6-P1_5  location_phx    sort        wait  training_0005-S6  \n",
       "training_0005-S6-P2_5  location_phx    sort  tail-aware  training_0005-S6  \n",
       "training_0005-S6-P3_5  location_phx    sort       eager  training_0005-S6  \n",
       "training_0005-S6-P4_5  location_phx    sort        wait  training_0005-S6  \n",
       "\n",
       "[244 rows x 22 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_predicted_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_policy_scores = {}\n",
    "for scenario_name, rows in best_predicted_configs.groupby([\"scenario_name\"]):\n",
    "    RF_policy_scores[scenario_name] = rows[\"ground_truth\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_0000-S0': 52.87870968605434,\n",
       " 'training_0000-S1': 30.171442191677876,\n",
       " 'training_0000-S10': 44.04496817360165,\n",
       " 'training_0000-S11': 22.344849911044943,\n",
       " 'training_0000-S12': 20.76592789628593,\n",
       " 'training_0000-S13': 71.56117520753163,\n",
       " 'training_0000-S14': 50.949531991086715,\n",
       " 'training_0000-S15': 24.52443757394675,\n",
       " 'training_0000-S16': 33.24979727916694,\n",
       " 'training_0000-S17': 23.57192840782397,\n",
       " 'training_0000-S18': 29.247405931099944,\n",
       " 'training_0000-S19': 71.51399117103918,\n",
       " 'training_0000-S2': 34.81908849354771,\n",
       " 'training_0000-S20': 64.56815684553558,\n",
       " 'training_0000-S21': 38.59336178643092,\n",
       " 'training_0000-S22': 23.56014459646689,\n",
       " 'training_0000-S23': 34.31612325219002,\n",
       " 'training_0000-S3': 63.98838702147525,\n",
       " 'training_0000-S4': 24.392940203206507,\n",
       " 'training_0000-S5': 35.28119022733358,\n",
       " 'training_0000-S6': 42.52468807688001,\n",
       " 'training_0002-S24': 22.815851070656066,\n",
       " 'training_0002-S4': 40.96797434616026,\n",
       " 'training_0002-S6': 5.826138330846304,\n",
       " 'training_0002-S9': 23.152843037447486,\n",
       " 'training_0003-S1': 20.616007996838707,\n",
       " 'training_0003-S11': 24.08066049183995,\n",
       " 'training_0003-S14': 57.49621790688857,\n",
       " 'training_0003-S16': 27.242991709320968,\n",
       " 'training_0003-S18': 42.50183327291062,\n",
       " 'training_0003-S20': 34.246688780744265,\n",
       " 'training_0003-S22': 75.20503617837007,\n",
       " 'training_0003-S24': 12.640340503233487,\n",
       " 'training_0003-S5': 60.87767780791036,\n",
       " 'training_0003-S7': 23.535663728790556,\n",
       " 'training_0003-S9': 22.632441185507908,\n",
       " 'training_0004-S1': 23.32494667550654,\n",
       " 'training_0004-S12': 35.39396973279513,\n",
       " 'training_0004-S14': 51.375671965518634,\n",
       " 'training_0004-S16': 31.685433044966874,\n",
       " 'training_0004-S19': 26.931686726478567,\n",
       " 'training_0004-S20': 35.601411418200236,\n",
       " 'training_0004-S22': 6.823432928375473,\n",
       " 'training_0004-S5': 21.38992342050014,\n",
       " 'training_0005-S0': 31.475167702946617,\n",
       " 'training_0005-S12': 36.652341952762214,\n",
       " 'training_0005-S19': 14.460300278504842,\n",
       " 'training_0005-S23': 77.710616951183,\n",
       " 'training_0005-S6': 20.82791331185077}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_policy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_policy_map = {}\n",
    "for index, row in best_predicted_configs.iterrows():\n",
    "    config_columns=[\"D-model\", \"D-conf\", \"D-seq-pol\", \"T-min-iou\", \"T-max-age\", \"T-every-nth-det\"]\n",
    "    RF_policy_map[index] = {c: row[c] for c in config_columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_0000-S0-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S0-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S0-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S0-P3_5': {'D-model': 'efficientdet-d6',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S0-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S1-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S1-P1_5': {'D-model': 'efficientdet-d1',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S1-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S1-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S1-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S10-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S10-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S10-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S10-P3_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S10-P4_5': {'D-model': 'efficientdet-d7',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S11-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S11-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S11-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S11-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S11-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S12-P0_5': {'D-model': 'efficientdet-d2',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S12-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S12-P2_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S12-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S12-P4_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S13-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S13-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S13-P2_5': {'D-model': 'efficientdet-d7',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S13-P3_5': {'D-model': 'efficientdet-d7',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S13-P4_5': {'D-model': 'efficientdet-d7',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S14-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S14-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S14-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S14-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S14-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S15-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S15-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S15-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S15-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S15-P4_5': {'D-model': 'efficientdet-d7',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S16-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S16-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S16-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S16-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S16-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S17-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S17-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S17-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S17-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S17-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S18-P0_5': {'D-model': 'efficientdet-d2',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S18-P1_5': {'D-model': 'efficientdet-d3',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S18-P2_5': {'D-model': 'efficientdet-d6',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S18-P3_5': {'D-model': 'efficientdet-d6',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S18-P4_5': {'D-model': 'efficientdet-d6',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S19-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S19-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S19-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S19-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S19-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S2-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S2-P1_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S2-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S2-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S2-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S20-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S20-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S20-P2_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S20-P3_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S20-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S21-P0_5': {'D-model': 'efficientdet-d1',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S21-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S21-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S21-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S21-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S22-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S22-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S22-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S22-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S22-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S23-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S23-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S23-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S23-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S23-P4_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S3-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S3-P1_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S3-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S3-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S3-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S4-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S4-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S4-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S4-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S4-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S5-P0_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S5-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S5-P2_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S5-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S5-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S6-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S6-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S6-P2_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S6-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0000-S6-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S24-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S24-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S24-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S24-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S24-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S4-P0_5': {'D-model': 'efficientdet-d6',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S4-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S4-P2_5': {'D-model': 'efficientdet-d2',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S4-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S4-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S6-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S6-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S6-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S6-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S6-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S9-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S9-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S9-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S9-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0002-S9-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S1-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S1-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S1-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S1-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S1-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S11-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S11-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S11-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S11-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S11-P4_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S14-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S14-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S14-P2_5': {'D-model': 'efficientdet-d6',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S14-P3_5': {'D-model': 'efficientdet-d6',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S14-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S16-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S16-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S16-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S16-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S16-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S18-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S18-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S18-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S18-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S18-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S20-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S20-P1_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S20-P2_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S20-P3_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S20-P4_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S22-P0_5': {'D-model': 'efficientdet-d6',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S22-P1_5': {'D-model': 'efficientdet-d7',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S22-P2_5': {'D-model': 'efficientdet-d6',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S22-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S22-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S24-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S24-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S24-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S24-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S24-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S5-P0_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S5-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S5-P2_5': {'D-model': 'efficientdet-d2',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S5-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S5-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S7-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S7-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S7-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S7-P3_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S7-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S9-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S9-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S9-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S9-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0003-S9-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S1-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S1-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S1-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S1-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S1-P4_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S12-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S12-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S12-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S12-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S12-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S14-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S14-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S14-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S14-P3_5': {'D-model': 'efficientdet-d6',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S14-P4_5': {'D-model': 'efficientdet-d7',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S16-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S16-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S16-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S16-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S16-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S19-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S19-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S19-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S19-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S19-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S20-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S20-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S20-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S20-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S20-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S22-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S22-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S22-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S22-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S22-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S5-P0_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S5-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S5-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S5-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0004-S5-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S0-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S0-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S0-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S0-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S0-P4_5': {'D-model': 'efficientdet-d7',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S12-P0_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S12-P1_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S12-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S12-P3_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S12-P4_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 7,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S19-P0_5': {'D-model': 'efficientdet-d2',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S19-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S19-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S19-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S19-P4_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S23-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S23-P2_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S23-P3_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S23-P4_5': {'D-model': 'efficientdet-d2',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S6-P0_5': {'D-model': 'efficientdet-d7x',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 3,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S6-P1_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.2,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S6-P2_5': {'D-model': 'efficientdet-d4',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'tail-aware',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 5,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S6-P3_5': {'D-model': 'efficientdet-d6',\n",
       "  'D-conf': 0.3,\n",
       "  'D-seq-pol': 'eager',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1},\n",
       " 'training_0005-S6-P4_5': {'D-model': 'efficientdet-d5',\n",
       "  'D-conf': 0.5,\n",
       "  'D-seq-pol': 'wait',\n",
       "  'T-min-iou': 0.1,\n",
       "  'T-max-age': 1,\n",
       "  'T-every-nth-det': 1}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_policy_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"RF_test_4s_grain_condensed_policy_map.pl\", 'wb') as f:\n",
    "    pickle.dump(RF_policy_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"RF_test_4s_grain_condensed_policy_scores.pl\", 'wb') as f:\n",
    "    pickle.dump(RF_policy_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
